{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 80)                480       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 243       \n",
      "=================================================================\n",
      "Total params: 723\n",
      "Trainable params: 723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/150\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.1023 - accuracy: 0.2375 - val_loss: 1.1716 - val_accuracy: 0.2500\n",
      "Epoch 2/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 1.0974 - accuracy: 0.2375 - val_loss: 1.1702 - val_accuracy: 0.2500\n",
      "Epoch 3/150\n",
      "80/80 [==============================] - 0s 57us/step - loss: 1.0933 - accuracy: 0.2625 - val_loss: 1.1685 - val_accuracy: 0.2500\n",
      "Epoch 4/150\n",
      "80/80 [==============================] - 0s 66us/step - loss: 1.0886 - accuracy: 0.2875 - val_loss: 1.1671 - val_accuracy: 0.2500\n",
      "Epoch 5/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 1.0843 - accuracy: 0.3375 - val_loss: 1.1655 - val_accuracy: 0.2500\n",
      "Epoch 6/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 1.0797 - accuracy: 0.3500 - val_loss: 1.1641 - val_accuracy: 0.2500\n",
      "Epoch 7/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 1.0754 - accuracy: 0.3750 - val_loss: 1.1626 - val_accuracy: 0.2500\n",
      "Epoch 8/150\n",
      "80/80 [==============================] - 0s 75us/step - loss: 1.0711 - accuracy: 0.3875 - val_loss: 1.1612 - val_accuracy: 0.2000\n",
      "Epoch 9/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 1.0668 - accuracy: 0.4250 - val_loss: 1.1597 - val_accuracy: 0.2000\n",
      "Epoch 10/150\n",
      "80/80 [==============================] - 0s 63us/step - loss: 1.0626 - accuracy: 0.4375 - val_loss: 1.1583 - val_accuracy: 0.2000\n",
      "Epoch 11/150\n",
      "80/80 [==============================] - 0s 52us/step - loss: 1.0585 - accuracy: 0.4625 - val_loss: 1.1569 - val_accuracy: 0.2000\n",
      "Epoch 12/150\n",
      "80/80 [==============================] - 0s 75us/step - loss: 1.0543 - accuracy: 0.5125 - val_loss: 1.1556 - val_accuracy: 0.2000\n",
      "Epoch 13/150\n",
      "80/80 [==============================] - 0s 50us/step - loss: 1.0503 - accuracy: 0.5125 - val_loss: 1.1543 - val_accuracy: 0.2000\n",
      "Epoch 14/150\n",
      "80/80 [==============================] - 0s 75us/step - loss: 1.0463 - accuracy: 0.5500 - val_loss: 1.1530 - val_accuracy: 0.2000\n",
      "Epoch 15/150\n",
      "80/80 [==============================] - 0s 50us/step - loss: 1.0424 - accuracy: 0.5500 - val_loss: 1.1518 - val_accuracy: 0.2000\n",
      "Epoch 16/150\n",
      "80/80 [==============================] - 0s 71us/step - loss: 1.0386 - accuracy: 0.5500 - val_loss: 1.1505 - val_accuracy: 0.2000\n",
      "Epoch 17/150\n",
      "80/80 [==============================] - 0s 57us/step - loss: 1.0348 - accuracy: 0.5625 - val_loss: 1.1492 - val_accuracy: 0.2000\n",
      "Epoch 18/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 1.0311 - accuracy: 0.5750 - val_loss: 1.1479 - val_accuracy: 0.2000\n",
      "Epoch 19/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 1.0274 - accuracy: 0.5750 - val_loss: 1.1466 - val_accuracy: 0.2000\n",
      "Epoch 20/150\n",
      "80/80 [==============================] - 0s 66us/step - loss: 1.0238 - accuracy: 0.5625 - val_loss: 1.1454 - val_accuracy: 0.2000\n",
      "Epoch 21/150\n",
      "80/80 [==============================] - 0s 75us/step - loss: 1.0202 - accuracy: 0.5750 - val_loss: 1.1441 - val_accuracy: 0.2000\n",
      "Epoch 22/150\n",
      "80/80 [==============================] - 0s 50us/step - loss: 1.0166 - accuracy: 0.5750 - val_loss: 1.1429 - val_accuracy: 0.2000\n",
      "Epoch 23/150\n",
      "80/80 [==============================] - 0s 75us/step - loss: 1.0131 - accuracy: 0.5750 - val_loss: 1.1417 - val_accuracy: 0.2000\n",
      "Epoch 24/150\n",
      "80/80 [==============================] - 0s 63us/step - loss: 1.0096 - accuracy: 0.5750 - val_loss: 1.1404 - val_accuracy: 0.2000\n",
      "Epoch 25/150\n",
      "80/80 [==============================] - 0s 57us/step - loss: 1.0061 - accuracy: 0.5750 - val_loss: 1.1392 - val_accuracy: 0.2000\n",
      "Epoch 26/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 1.0027 - accuracy: 0.5750 - val_loss: 1.1380 - val_accuracy: 0.2000\n",
      "Epoch 27/150\n",
      "80/80 [==============================] - 0s 75us/step - loss: 0.9993 - accuracy: 0.5750 - val_loss: 1.1368 - val_accuracy: 0.2000\n",
      "Epoch 28/150\n",
      "80/80 [==============================] - 0s 74us/step - loss: 0.9958 - accuracy: 0.5750 - val_loss: 1.1356 - val_accuracy: 0.2000\n",
      "Epoch 29/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.9925 - accuracy: 0.5875 - val_loss: 1.1345 - val_accuracy: 0.2000\n",
      "Epoch 30/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.9891 - accuracy: 0.6250 - val_loss: 1.1333 - val_accuracy: 0.2000\n",
      "Epoch 31/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.9858 - accuracy: 0.6375 - val_loss: 1.1321 - val_accuracy: 0.2000\n",
      "Epoch 32/150\n",
      "80/80 [==============================] - 0s 75us/step - loss: 0.9825 - accuracy: 0.6375 - val_loss: 1.1309 - val_accuracy: 0.2000\n",
      "Epoch 33/150\n",
      "80/80 [==============================] - 0s 46us/step - loss: 0.9792 - accuracy: 0.6375 - val_loss: 1.1297 - val_accuracy: 0.2000\n",
      "Epoch 34/150\n",
      "80/80 [==============================] - 0s 87us/step - loss: 0.9759 - accuracy: 0.6375 - val_loss: 1.1285 - val_accuracy: 0.2000\n",
      "Epoch 35/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.9726 - accuracy: 0.6375 - val_loss: 1.1274 - val_accuracy: 0.2000\n",
      "Epoch 36/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.9693 - accuracy: 0.6375 - val_loss: 1.1262 - val_accuracy: 0.2000\n",
      "Epoch 37/150\n",
      "80/80 [==============================] - 0s 50us/step - loss: 0.9661 - accuracy: 0.6375 - val_loss: 1.1251 - val_accuracy: 0.2000\n",
      "Epoch 38/150\n",
      "80/80 [==============================] - 0s 75us/step - loss: 0.9628 - accuracy: 0.6375 - val_loss: 1.1239 - val_accuracy: 0.2000\n",
      "Epoch 39/150\n",
      "80/80 [==============================] - 0s 50us/step - loss: 0.9595 - accuracy: 0.6375 - val_loss: 1.1228 - val_accuracy: 0.2000\n",
      "Epoch 40/150\n",
      "80/80 [==============================] - 0s 43us/step - loss: 0.9562 - accuracy: 0.6375 - val_loss: 1.1217 - val_accuracy: 0.2000\n",
      "Epoch 41/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.9529 - accuracy: 0.6375 - val_loss: 1.1205 - val_accuracy: 0.2000\n",
      "Epoch 42/150\n",
      "80/80 [==============================] - 0s 38us/step - loss: 0.9496 - accuracy: 0.6375 - val_loss: 1.1194 - val_accuracy: 0.2000\n",
      "Epoch 43/150\n",
      "80/80 [==============================] - 0s 37us/step - loss: 0.9463 - accuracy: 0.6375 - val_loss: 1.1183 - val_accuracy: 0.2000\n",
      "Epoch 44/150\n",
      "80/80 [==============================] - 0s 37us/step - loss: 0.9430 - accuracy: 0.6375 - val_loss: 1.1171 - val_accuracy: 0.2000\n",
      "Epoch 45/150\n",
      "80/80 [==============================] - 0s 37us/step - loss: 0.9397 - accuracy: 0.6500 - val_loss: 1.1160 - val_accuracy: 0.2000\n",
      "Epoch 46/150\n",
      "80/80 [==============================] - 0s 25us/step - loss: 0.9364 - accuracy: 0.6500 - val_loss: 1.1149 - val_accuracy: 0.2000\n",
      "Epoch 47/150\n",
      "80/80 [==============================] - 0s 37us/step - loss: 0.9331 - accuracy: 0.6500 - val_loss: 1.1138 - val_accuracy: 0.2000\n",
      "Epoch 48/150\n",
      "80/80 [==============================] - 0s 50us/step - loss: 0.9298 - accuracy: 0.6500 - val_loss: 1.1127 - val_accuracy: 0.2000\n",
      "Epoch 49/150\n",
      "80/80 [==============================] - 0s 37us/step - loss: 0.9265 - accuracy: 0.6625 - val_loss: 1.1115 - val_accuracy: 0.2000\n",
      "Epoch 50/150\n",
      "80/80 [==============================] - 0s 25us/step - loss: 0.9232 - accuracy: 0.6625 - val_loss: 1.1104 - val_accuracy: 0.2000\n",
      "Epoch 51/150\n",
      "80/80 [==============================] - 0s 49us/step - loss: 0.9198 - accuracy: 0.6625 - val_loss: 1.1093 - val_accuracy: 0.2000\n",
      "Epoch 52/150\n",
      "80/80 [==============================] - 0s 38us/step - loss: 0.9164 - accuracy: 0.6625 - val_loss: 1.1082 - val_accuracy: 0.2000\n",
      "Epoch 53/150\n",
      "80/80 [==============================] - 0s 37us/step - loss: 0.9131 - accuracy: 0.6625 - val_loss: 1.1071 - val_accuracy: 0.2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/150\n",
      "80/80 [==============================] - 0s 25us/step - loss: 0.9097 - accuracy: 0.6625 - val_loss: 1.1060 - val_accuracy: 0.2000\n",
      "Epoch 55/150\n",
      "80/80 [==============================] - 0s 34us/step - loss: 0.9063 - accuracy: 0.6500 - val_loss: 1.1049 - val_accuracy: 0.2000\n",
      "Epoch 56/150\n",
      "80/80 [==============================] - 0s 46us/step - loss: 0.9029 - accuracy: 0.6500 - val_loss: 1.1038 - val_accuracy: 0.2000\n",
      "Epoch 57/150\n",
      "80/80 [==============================] - 0s 37us/step - loss: 0.8995 - accuracy: 0.6500 - val_loss: 1.1027 - val_accuracy: 0.2000\n",
      "Epoch 58/150\n",
      "80/80 [==============================] - 0s 44us/step - loss: 0.8960 - accuracy: 0.6500 - val_loss: 1.1016 - val_accuracy: 0.2000\n",
      "Epoch 59/150\n",
      "80/80 [==============================] - 0s 49us/step - loss: 0.8926 - accuracy: 0.6500 - val_loss: 1.1005 - val_accuracy: 0.2000\n",
      "Epoch 60/150\n",
      "80/80 [==============================] - 0s 53us/step - loss: 0.8891 - accuracy: 0.6500 - val_loss: 1.0994 - val_accuracy: 0.2000\n",
      "Epoch 61/150\n",
      "80/80 [==============================] - 0s 49us/step - loss: 0.8857 - accuracy: 0.6625 - val_loss: 1.0984 - val_accuracy: 0.2000\n",
      "Epoch 62/150\n",
      "80/80 [==============================] - 0s 49us/step - loss: 0.8822 - accuracy: 0.6625 - val_loss: 1.0973 - val_accuracy: 0.2000\n",
      "Epoch 63/150\n",
      "80/80 [==============================] - 0s 49us/step - loss: 0.8787 - accuracy: 0.6625 - val_loss: 1.0962 - val_accuracy: 0.2000\n",
      "Epoch 64/150\n",
      "80/80 [==============================] - 0s 49us/step - loss: 0.8752 - accuracy: 0.6625 - val_loss: 1.0951 - val_accuracy: 0.2000\n",
      "Epoch 65/150\n",
      "80/80 [==============================] - 0s 50us/step - loss: 0.8717 - accuracy: 0.6625 - val_loss: 1.0940 - val_accuracy: 0.2000\n",
      "Epoch 66/150\n",
      "80/80 [==============================] - 0s 37us/step - loss: 0.8682 - accuracy: 0.6625 - val_loss: 1.0930 - val_accuracy: 0.2000\n",
      "Epoch 67/150\n",
      "80/80 [==============================] - 0s 35us/step - loss: 0.8646 - accuracy: 0.6625 - val_loss: 1.0919 - val_accuracy: 0.2000\n",
      "Epoch 68/150\n",
      "80/80 [==============================] - 0s 25us/step - loss: 0.8611 - accuracy: 0.6625 - val_loss: 1.0908 - val_accuracy: 0.2000\n",
      "Epoch 69/150\n",
      "80/80 [==============================] - 0s 50us/step - loss: 0.8575 - accuracy: 0.6625 - val_loss: 1.0897 - val_accuracy: 0.2000\n",
      "Epoch 70/150\n",
      "80/80 [==============================] - 0s 38us/step - loss: 0.8539 - accuracy: 0.6625 - val_loss: 1.0886 - val_accuracy: 0.2000\n",
      "Epoch 71/150\n",
      "80/80 [==============================] - 0s 39us/step - loss: 0.8504 - accuracy: 0.6750 - val_loss: 1.0874 - val_accuracy: 0.2000\n",
      "Epoch 72/150\n",
      "80/80 [==============================] - 0s 38us/step - loss: 0.8468 - accuracy: 0.6750 - val_loss: 1.0863 - val_accuracy: 0.2000\n",
      "Epoch 73/150\n",
      "80/80 [==============================] - 0s 53us/step - loss: 0.8432 - accuracy: 0.6750 - val_loss: 1.0851 - val_accuracy: 0.2000\n",
      "Epoch 74/150\n",
      "80/80 [==============================] - 0s 37us/step - loss: 0.8396 - accuracy: 0.6750 - val_loss: 1.0840 - val_accuracy: 0.2000\n",
      "Epoch 75/150\n",
      "80/80 [==============================] - 0s 48us/step - loss: 0.8360 - accuracy: 0.6750 - val_loss: 1.0828 - val_accuracy: 0.2000\n",
      "Epoch 76/150\n",
      "80/80 [==============================] - 0s 43us/step - loss: 0.8324 - accuracy: 0.6750 - val_loss: 1.0816 - val_accuracy: 0.2000\n",
      "Epoch 77/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.8288 - accuracy: 0.6750 - val_loss: 1.0805 - val_accuracy: 0.2000\n",
      "Epoch 78/150\n",
      "80/80 [==============================] - 0s 38us/step - loss: 0.8252 - accuracy: 0.6750 - val_loss: 1.0793 - val_accuracy: 0.2000\n",
      "Epoch 79/150\n",
      "80/80 [==============================] - 0s 37us/step - loss: 0.8216 - accuracy: 0.6750 - val_loss: 1.0781 - val_accuracy: 0.2000\n",
      "Epoch 80/150\n",
      "80/80 [==============================] - 0s 35us/step - loss: 0.8180 - accuracy: 0.6750 - val_loss: 1.0769 - val_accuracy: 0.2000\n",
      "Epoch 81/150\n",
      "80/80 [==============================] - 0s 40us/step - loss: 0.8143 - accuracy: 0.6750 - val_loss: 1.0758 - val_accuracy: 0.2000\n",
      "Epoch 82/150\n",
      "80/80 [==============================] - 0s 50us/step - loss: 0.8108 - accuracy: 0.6750 - val_loss: 1.0746 - val_accuracy: 0.2000\n",
      "Epoch 83/150\n",
      "80/80 [==============================] - 0s 42us/step - loss: 0.8071 - accuracy: 0.6750 - val_loss: 1.0734 - val_accuracy: 0.2000\n",
      "Epoch 84/150\n",
      "80/80 [==============================] - 0s 49us/step - loss: 0.8035 - accuracy: 0.6875 - val_loss: 1.0723 - val_accuracy: 0.2000\n",
      "Epoch 85/150\n",
      "80/80 [==============================] - 0s 63us/step - loss: 0.7999 - accuracy: 0.6875 - val_loss: 1.0712 - val_accuracy: 0.2000\n",
      "Epoch 86/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.7963 - accuracy: 0.6875 - val_loss: 1.0701 - val_accuracy: 0.2000\n",
      "Epoch 87/150\n",
      "80/80 [==============================] - 0s 55us/step - loss: 0.7927 - accuracy: 0.7000 - val_loss: 1.0690 - val_accuracy: 0.2000\n",
      "Epoch 88/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.7892 - accuracy: 0.7125 - val_loss: 1.0679 - val_accuracy: 0.2000\n",
      "Epoch 89/150\n",
      "80/80 [==============================] - 0s 60us/step - loss: 0.7856 - accuracy: 0.7125 - val_loss: 1.0668 - val_accuracy: 0.2000\n",
      "Epoch 90/150\n",
      "80/80 [==============================] - 0s 58us/step - loss: 0.7820 - accuracy: 0.7125 - val_loss: 1.0658 - val_accuracy: 0.2000\n",
      "Epoch 91/150\n",
      "80/80 [==============================] - 0s 75us/step - loss: 0.7785 - accuracy: 0.7125 - val_loss: 1.0647 - val_accuracy: 0.2000\n",
      "Epoch 92/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.7749 - accuracy: 0.7125 - val_loss: 1.0637 - val_accuracy: 0.2000\n",
      "Epoch 93/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.7714 - accuracy: 0.7250 - val_loss: 1.0627 - val_accuracy: 0.2000\n",
      "Epoch 94/150\n",
      "80/80 [==============================] - 0s 63us/step - loss: 0.7679 - accuracy: 0.7250 - val_loss: 1.0617 - val_accuracy: 0.2000\n",
      "Epoch 95/150\n",
      "80/80 [==============================] - 0s 63us/step - loss: 0.7644 - accuracy: 0.7250 - val_loss: 1.0607 - val_accuracy: 0.2000\n",
      "Epoch 96/150\n",
      "80/80 [==============================] - 0s 63us/step - loss: 0.7608 - accuracy: 0.7375 - val_loss: 1.0598 - val_accuracy: 0.2000\n",
      "Epoch 97/150\n",
      "80/80 [==============================] - 0s 50us/step - loss: 0.7573 - accuracy: 0.7375 - val_loss: 1.0588 - val_accuracy: 0.2000\n",
      "Epoch 98/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.7538 - accuracy: 0.7375 - val_loss: 1.0579 - val_accuracy: 0.2000\n",
      "Epoch 99/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.7503 - accuracy: 0.7375 - val_loss: 1.0570 - val_accuracy: 0.2000\n",
      "Epoch 100/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.7468 - accuracy: 0.7625 - val_loss: 1.0561 - val_accuracy: 0.2000\n",
      "Epoch 101/150\n",
      "80/80 [==============================] - 0s 57us/step - loss: 0.7433 - accuracy: 0.7625 - val_loss: 1.0552 - val_accuracy: 0.2000\n",
      "Epoch 102/150\n",
      "80/80 [==============================] - 0s 67us/step - loss: 0.7399 - accuracy: 0.7625 - val_loss: 1.0543 - val_accuracy: 0.2000\n",
      "Epoch 103/150\n",
      "80/80 [==============================] - 0s 50us/step - loss: 0.7365 - accuracy: 0.7625 - val_loss: 1.0535 - val_accuracy: 0.2500\n",
      "Epoch 104/150\n",
      "80/80 [==============================] - 0s 50us/step - loss: 0.7331 - accuracy: 0.7625 - val_loss: 1.0527 - val_accuracy: 0.2500\n",
      "Epoch 105/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.7298 - accuracy: 0.7625 - val_loss: 1.0519 - val_accuracy: 0.2500\n",
      "Epoch 106/150\n",
      "80/80 [==============================] - 0s 75us/step - loss: 0.7265 - accuracy: 0.7625 - val_loss: 1.0511 - val_accuracy: 0.2500\n",
      "Epoch 107/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.7233 - accuracy: 0.7750 - val_loss: 1.0503 - val_accuracy: 0.2500\n",
      "Epoch 108/150\n",
      "80/80 [==============================] - 0s 63us/step - loss: 0.7201 - accuracy: 0.7750 - val_loss: 1.0496 - val_accuracy: 0.2500\n",
      "Epoch 109/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.7169 - accuracy: 0.7750 - val_loss: 1.0489 - val_accuracy: 0.2500\n",
      "Epoch 110/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.7137 - accuracy: 0.7750 - val_loss: 1.0483 - val_accuracy: 0.2500\n",
      "Epoch 111/150\n",
      "80/80 [==============================] - 0s 50us/step - loss: 0.7106 - accuracy: 0.7625 - val_loss: 1.0476 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.7075 - accuracy: 0.7625 - val_loss: 1.0470 - val_accuracy: 0.2500\n",
      "Epoch 113/150\n",
      "80/80 [==============================] - 0s 50us/step - loss: 0.7044 - accuracy: 0.7625 - val_loss: 1.0465 - val_accuracy: 0.2500\n",
      "Epoch 114/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.7013 - accuracy: 0.7750 - val_loss: 1.0459 - val_accuracy: 0.2500\n",
      "Epoch 115/150\n",
      "80/80 [==============================] - 0s 63us/step - loss: 0.6982 - accuracy: 0.7750 - val_loss: 1.0454 - val_accuracy: 0.2500\n",
      "Epoch 116/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.6952 - accuracy: 0.7750 - val_loss: 1.0449 - val_accuracy: 0.2500\n",
      "Epoch 117/150\n",
      "80/80 [==============================] - 0s 58us/step - loss: 0.6922 - accuracy: 0.7750 - val_loss: 1.0445 - val_accuracy: 0.3000\n",
      "Epoch 118/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.6892 - accuracy: 0.7625 - val_loss: 1.0442 - val_accuracy: 0.3000\n",
      "Epoch 119/150\n",
      "80/80 [==============================] - 0s 50us/step - loss: 0.6862 - accuracy: 0.7500 - val_loss: 1.0439 - val_accuracy: 0.3000\n",
      "Epoch 120/150\n",
      "80/80 [==============================] - 0s 75us/step - loss: 0.6833 - accuracy: 0.7500 - val_loss: 1.0437 - val_accuracy: 0.3000\n",
      "Epoch 121/150\n",
      "80/80 [==============================] - 0s 52us/step - loss: 0.6804 - accuracy: 0.7500 - val_loss: 1.0436 - val_accuracy: 0.3000\n",
      "Epoch 122/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.6775 - accuracy: 0.7500 - val_loss: 1.0434 - val_accuracy: 0.3000\n",
      "Epoch 123/150\n",
      "80/80 [==============================] - 0s 63us/step - loss: 0.6747 - accuracy: 0.7500 - val_loss: 1.0434 - val_accuracy: 0.3000\n",
      "Epoch 124/150\n",
      "80/80 [==============================] - 0s 50us/step - loss: 0.6719 - accuracy: 0.7500 - val_loss: 1.0433 - val_accuracy: 0.3000\n",
      "Epoch 125/150\n",
      "80/80 [==============================] - 0s 63us/step - loss: 0.6691 - accuracy: 0.7500 - val_loss: 1.0433 - val_accuracy: 0.3000\n",
      "Epoch 126/150\n",
      "80/80 [==============================] - 0s 50us/step - loss: 0.6663 - accuracy: 0.7625 - val_loss: 1.0433 - val_accuracy: 0.3000\n",
      "Epoch 127/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.6636 - accuracy: 0.7625 - val_loss: 1.0434 - val_accuracy: 0.3000\n",
      "Epoch 128/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.6608 - accuracy: 0.7625 - val_loss: 1.0435 - val_accuracy: 0.3000\n",
      "Epoch 129/150\n",
      "80/80 [==============================] - 0s 63us/step - loss: 0.6581 - accuracy: 0.7625 - val_loss: 1.0437 - val_accuracy: 0.3000\n",
      "Epoch 130/150\n",
      "80/80 [==============================] - 0s 58us/step - loss: 0.6555 - accuracy: 0.7625 - val_loss: 1.0439 - val_accuracy: 0.3000\n",
      "Epoch 131/150\n",
      "80/80 [==============================] - 0s 50us/step - loss: 0.6529 - accuracy: 0.7625 - val_loss: 1.0441 - val_accuracy: 0.3000\n",
      "Epoch 132/150\n",
      "80/80 [==============================] - 0s 63us/step - loss: 0.6503 - accuracy: 0.7625 - val_loss: 1.0444 - val_accuracy: 0.3000\n",
      "Epoch 133/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.6478 - accuracy: 0.7625 - val_loss: 1.0448 - val_accuracy: 0.3000\n",
      "Epoch 134/150\n",
      "80/80 [==============================] - 0s 57us/step - loss: 0.6452 - accuracy: 0.7625 - val_loss: 1.0453 - val_accuracy: 0.3000\n",
      "Epoch 135/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.6427 - accuracy: 0.7625 - val_loss: 1.0458 - val_accuracy: 0.3000\n",
      "Epoch 136/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.6403 - accuracy: 0.7500 - val_loss: 1.0463 - val_accuracy: 0.3000\n",
      "Epoch 137/150\n",
      "80/80 [==============================] - 0s 50us/step - loss: 0.6378 - accuracy: 0.7500 - val_loss: 1.0469 - val_accuracy: 0.3000\n",
      "Epoch 138/150\n",
      "80/80 [==============================] - 0s 74us/step - loss: 0.6354 - accuracy: 0.7500 - val_loss: 1.0476 - val_accuracy: 0.3000\n",
      "Epoch 139/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.6330 - accuracy: 0.7625 - val_loss: 1.0482 - val_accuracy: 0.3000\n",
      "Epoch 140/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.6307 - accuracy: 0.7625 - val_loss: 1.0490 - val_accuracy: 0.3000\n",
      "Epoch 141/150\n",
      "80/80 [==============================] - 0s 50us/step - loss: 0.6283 - accuracy: 0.7625 - val_loss: 1.0498 - val_accuracy: 0.3000\n",
      "Epoch 142/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.6259 - accuracy: 0.7625 - val_loss: 1.0506 - val_accuracy: 0.3000\n",
      "Epoch 143/150\n",
      "80/80 [==============================] - 0s 63us/step - loss: 0.6236 - accuracy: 0.7625 - val_loss: 1.0515 - val_accuracy: 0.3000\n",
      "Epoch 144/150\n",
      "80/80 [==============================] - 0s 49us/step - loss: 0.6214 - accuracy: 0.7625 - val_loss: 1.0524 - val_accuracy: 0.3000\n",
      "Epoch 145/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.6192 - accuracy: 0.7625 - val_loss: 1.0535 - val_accuracy: 0.3000\n",
      "Epoch 146/150\n",
      "80/80 [==============================] - 0s 50us/step - loss: 0.6170 - accuracy: 0.7625 - val_loss: 1.0545 - val_accuracy: 0.3000\n",
      "Epoch 147/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.6148 - accuracy: 0.7625 - val_loss: 1.0557 - val_accuracy: 0.3000\n",
      "Epoch 148/150\n",
      "80/80 [==============================] - 0s 50us/step - loss: 0.6126 - accuracy: 0.7750 - val_loss: 1.0568 - val_accuracy: 0.3000\n",
      "Epoch 149/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.6105 - accuracy: 0.7750 - val_loss: 1.0581 - val_accuracy: 0.3000\n",
      "Epoch 150/150\n",
      "80/80 [==============================] - 0s 62us/step - loss: 0.6084 - accuracy: 0.7750 - val_loss: 1.0594 - val_accuracy: 0.3000\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model \n",
    "from keras.layers.core import Dense, Dropout, Flatten, Activation \n",
    "from sklearn import preprocessing\n",
    "import csv\n",
    "import pandas as pd\n",
    "with open('013_b_1114_1_2_p1.csv', newline='') as csvfile1:\n",
    "    data1 = pd.read_csv(csvfile1)\n",
    "    data1 = data1[0:100]\n",
    "with open('014_b_1114_1_2_p2.csv', newline='') as csvfile2:\n",
    "    data2 = pd.read_csv(csvfile2)\n",
    "    data2 = data2[0:100]\n",
    "    \n",
    "X = data1.loc[:,['p1Cash','StockPrice','p1TotalAsset']]\n",
    "X['p2TotalAsset'] = data2.loc[:,['p2TotalAsset']]\n",
    "X['p1ChechHistory'] = pd.get_dummies(data1.loc[:,'p1ChechHistory'])['yes']\n",
    "X = preprocessing.scale(X, axis = 0)\n",
    "\n",
    "    \n",
    "Y = data1.loc[:,'p1Decision']\n",
    "Y_dum = pd.get_dummies(Y)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(80, input_dim = 5, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "test = model.fit(X,Y_dum, epochs = 150, batch_size = 80, validation_split = 0.2, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "轉換columns名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(test.history['accuracy'])\n",
    "plt.plot(test.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(test.history['loss'])\n",
    "plt.plot(test.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('001_b_1110_1_1_p1.csv', newline='') as csvfile1:\n",
    "    data1 = pd.read_csv(csvfile1)\n",
    "with open('002_b_1110_1_1_p2.csv', newline='') as csvfile2:\n",
    "    data2 = pd.read_csv(csvfile2)\n",
    "data1 = data1.rename(columns = {'p1Cash':'Cash','StockPrice':'StockPrice','p1TotalAsset':'TotalAsset',\n",
    "                                'p1ChechHistory':'ChechHistory'}, inplace = False)\n",
    "\n",
    "X = data1.loc[:,['Cash','StockPrice','TotalAsset']]\n",
    "X['TotalAsset'] = data2.loc[:,['TotalAsset']]\n",
    "X['p1ChechHistory'] = pd.get_dummies(data1.loc[:,'p1ChechHistory'])['yes']\n",
    "X_1_101 = X[1:101]\n",
    "X_1_101 = X_1_101.reset_index()\n",
    "X_0_100 = X[0:100]\n",
    "X_0_100 = X_0_100.rename(columns = {'p1Cash':'pre_p1Cash','StockPrice':'pre_StockPrice','p1TotalAsset':'pre_p1TotalAsset',\n",
    "                                   'p2TotalAsset':'pre_p2TotalAsset','p1ChechHistory':'pre_p1ChechHistory'}, inplace = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_63 (Dense)             (None, 80)                880       \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 3)                 243       \n",
      "=================================================================\n",
      "Total params: 1,123\n",
      "Trainable params: 1,123\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 79 samples, validate on 20 samples\n",
      "Epoch 1/500\n",
      "79/79 [==============================] - 0s 858us/step - loss: 1.1531 - accuracy: 0.2405 - val_loss: 1.2397 - val_accuracy: 0.2000\n",
      "Epoch 2/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 1.1461 - accuracy: 0.2532 - val_loss: 1.2393 - val_accuracy: 0.2000\n",
      "Epoch 3/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 1.1369 - accuracy: 0.2532 - val_loss: 1.2389 - val_accuracy: 0.2000\n",
      "Epoch 4/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 1.1287 - accuracy: 0.2532 - val_loss: 1.2384 - val_accuracy: 0.2000\n",
      "Epoch 5/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 1.1206 - accuracy: 0.2532 - val_loss: 1.2380 - val_accuracy: 0.1500\n",
      "Epoch 6/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 1.1126 - accuracy: 0.2658 - val_loss: 1.2374 - val_accuracy: 0.1500\n",
      "Epoch 7/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 1.1048 - accuracy: 0.3165 - val_loss: 1.2368 - val_accuracy: 0.1500\n",
      "Epoch 8/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 1.0972 - accuracy: 0.3418 - val_loss: 1.2361 - val_accuracy: 0.1500\n",
      "Epoch 9/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 1.0899 - accuracy: 0.3544 - val_loss: 1.2355 - val_accuracy: 0.1500\n",
      "Epoch 10/500\n",
      "79/79 [==============================] - 0s 37us/step - loss: 1.0828 - accuracy: 0.3671 - val_loss: 1.2348 - val_accuracy: 0.1500\n",
      "Epoch 11/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 1.0759 - accuracy: 0.3924 - val_loss: 1.2342 - val_accuracy: 0.0500\n",
      "Epoch 12/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 1.0693 - accuracy: 0.3924 - val_loss: 1.2336 - val_accuracy: 0.0500\n",
      "Epoch 13/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 1.0629 - accuracy: 0.3924 - val_loss: 1.2331 - val_accuracy: 0.0500\n",
      "Epoch 14/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 1.0567 - accuracy: 0.4051 - val_loss: 1.2327 - val_accuracy: 0.0500\n",
      "Epoch 15/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 1.0508 - accuracy: 0.4177 - val_loss: 1.2323 - val_accuracy: 0.0500\n",
      "Epoch 16/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 1.0451 - accuracy: 0.4304 - val_loss: 1.2320 - val_accuracy: 0.0500\n",
      "Epoch 17/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 1.0395 - accuracy: 0.4430 - val_loss: 1.2319 - val_accuracy: 0.0500\n",
      "Epoch 18/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 1.0341 - accuracy: 0.4557 - val_loss: 1.2318 - val_accuracy: 0.0500\n",
      "Epoch 19/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 1.0289 - accuracy: 0.4557 - val_loss: 1.2317 - val_accuracy: 0.0500\n",
      "Epoch 20/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 1.0239 - accuracy: 0.4557 - val_loss: 1.2317 - val_accuracy: 0.1000\n",
      "Epoch 21/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 1.0191 - accuracy: 0.4557 - val_loss: 1.2317 - val_accuracy: 0.0500\n",
      "Epoch 22/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 1.0143 - accuracy: 0.4557 - val_loss: 1.2318 - val_accuracy: 0.1000\n",
      "Epoch 23/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 1.0096 - accuracy: 0.4557 - val_loss: 1.2321 - val_accuracy: 0.1000\n",
      "Epoch 24/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 1.0051 - accuracy: 0.4684 - val_loss: 1.2325 - val_accuracy: 0.1000\n",
      "Epoch 25/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 1.0007 - accuracy: 0.4684 - val_loss: 1.2331 - val_accuracy: 0.1500\n",
      "Epoch 26/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.9963 - accuracy: 0.4684 - val_loss: 1.2338 - val_accuracy: 0.1500\n",
      "Epoch 27/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.9921 - accuracy: 0.4684 - val_loss: 1.2346 - val_accuracy: 0.1500\n",
      "Epoch 28/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9880 - accuracy: 0.4684 - val_loss: 1.2355 - val_accuracy: 0.1500\n",
      "Epoch 29/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.9839 - accuracy: 0.4810 - val_loss: 1.2366 - val_accuracy: 0.1500\n",
      "Epoch 30/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9799 - accuracy: 0.4810 - val_loss: 1.2376 - val_accuracy: 0.1500\n",
      "Epoch 31/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.9760 - accuracy: 0.4810 - val_loss: 1.2389 - val_accuracy: 0.1500\n",
      "Epoch 32/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.9722 - accuracy: 0.4937 - val_loss: 1.2402 - val_accuracy: 0.1500\n",
      "Epoch 33/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9685 - accuracy: 0.4937 - val_loss: 1.2416 - val_accuracy: 0.1500\n",
      "Epoch 34/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9647 - accuracy: 0.4937 - val_loss: 1.2432 - val_accuracy: 0.1500\n",
      "Epoch 35/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.9611 - accuracy: 0.5063 - val_loss: 1.2449 - val_accuracy: 0.1500\n",
      "Epoch 36/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.9574 - accuracy: 0.5190 - val_loss: 1.2467 - val_accuracy: 0.1500\n",
      "Epoch 37/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9538 - accuracy: 0.5190 - val_loss: 1.2486 - val_accuracy: 0.1500\n",
      "Epoch 38/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9503 - accuracy: 0.5190 - val_loss: 1.2507 - val_accuracy: 0.1500\n",
      "Epoch 39/500\n",
      "79/79 [==============================] - 0s 37us/step - loss: 0.9468 - accuracy: 0.5190 - val_loss: 1.2528 - val_accuracy: 0.1500\n",
      "Epoch 40/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9434 - accuracy: 0.5190 - val_loss: 1.2549 - val_accuracy: 0.1500\n",
      "Epoch 41/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9401 - accuracy: 0.5190 - val_loss: 1.2571 - val_accuracy: 0.1500\n",
      "Epoch 42/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9367 - accuracy: 0.5190 - val_loss: 1.2593 - val_accuracy: 0.1500\n",
      "Epoch 43/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9334 - accuracy: 0.5190 - val_loss: 1.2617 - val_accuracy: 0.1500\n",
      "Epoch 44/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9301 - accuracy: 0.5190 - val_loss: 1.2640 - val_accuracy: 0.1500\n",
      "Epoch 45/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9269 - accuracy: 0.5316 - val_loss: 1.2664 - val_accuracy: 0.1500\n",
      "Epoch 46/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.9237 - accuracy: 0.5443 - val_loss: 1.2690 - val_accuracy: 0.1500\n",
      "Epoch 47/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9205 - accuracy: 0.5443 - val_loss: 1.2717 - val_accuracy: 0.1500\n",
      "Epoch 48/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9174 - accuracy: 0.5443 - val_loss: 1.2744 - val_accuracy: 0.1500\n",
      "Epoch 49/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9143 - accuracy: 0.5443 - val_loss: 1.2773 - val_accuracy: 0.1500\n",
      "Epoch 50/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.9112 - accuracy: 0.5443 - val_loss: 1.2804 - val_accuracy: 0.1500\n",
      "Epoch 51/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9081 - accuracy: 0.5443 - val_loss: 1.2837 - val_accuracy: 0.1500\n",
      "Epoch 52/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9050 - accuracy: 0.5443 - val_loss: 1.2871 - val_accuracy: 0.1500\n",
      "Epoch 53/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9019 - accuracy: 0.5443 - val_loss: 1.2906 - val_accuracy: 0.1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8989 - accuracy: 0.5443 - val_loss: 1.2943 - val_accuracy: 0.1500\n",
      "Epoch 55/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8959 - accuracy: 0.5570 - val_loss: 1.2981 - val_accuracy: 0.1500\n",
      "Epoch 56/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8929 - accuracy: 0.5696 - val_loss: 1.3020 - val_accuracy: 0.1500\n",
      "Epoch 57/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8899 - accuracy: 0.5696 - val_loss: 1.3060 - val_accuracy: 0.1500\n",
      "Epoch 58/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.8870 - accuracy: 0.5823 - val_loss: 1.3101 - val_accuracy: 0.1500\n",
      "Epoch 59/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8840 - accuracy: 0.5823 - val_loss: 1.3142 - val_accuracy: 0.1500\n",
      "Epoch 60/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8811 - accuracy: 0.5823 - val_loss: 1.3184 - val_accuracy: 0.1500\n",
      "Epoch 61/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.8783 - accuracy: 0.5949 - val_loss: 1.3227 - val_accuracy: 0.1500\n",
      "Epoch 62/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8754 - accuracy: 0.5949 - val_loss: 1.3271 - val_accuracy: 0.1500\n",
      "Epoch 63/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8726 - accuracy: 0.5949 - val_loss: 1.3317 - val_accuracy: 0.1500\n",
      "Epoch 64/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8698 - accuracy: 0.5949 - val_loss: 1.3364 - val_accuracy: 0.1500\n",
      "Epoch 65/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.8671 - accuracy: 0.5949 - val_loss: 1.3412 - val_accuracy: 0.1500\n",
      "Epoch 66/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8643 - accuracy: 0.5949 - val_loss: 1.3460 - val_accuracy: 0.1500\n",
      "Epoch 67/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8617 - accuracy: 0.5949 - val_loss: 1.3509 - val_accuracy: 0.1500\n",
      "Epoch 68/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.8590 - accuracy: 0.5949 - val_loss: 1.3558 - val_accuracy: 0.1500\n",
      "Epoch 69/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8563 - accuracy: 0.5949 - val_loss: 1.3609 - val_accuracy: 0.1500\n",
      "Epoch 70/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8537 - accuracy: 0.6076 - val_loss: 1.3660 - val_accuracy: 0.1500\n",
      "Epoch 71/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8511 - accuracy: 0.6076 - val_loss: 1.3713 - val_accuracy: 0.2000\n",
      "Epoch 72/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8485 - accuracy: 0.6076 - val_loss: 1.3767 - val_accuracy: 0.2000\n",
      "Epoch 73/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8459 - accuracy: 0.6076 - val_loss: 1.3822 - val_accuracy: 0.2000\n",
      "Epoch 74/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.8434 - accuracy: 0.6076 - val_loss: 1.3879 - val_accuracy: 0.2000\n",
      "Epoch 75/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8409 - accuracy: 0.5949 - val_loss: 1.3939 - val_accuracy: 0.2000\n",
      "Epoch 76/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8383 - accuracy: 0.5949 - val_loss: 1.4001 - val_accuracy: 0.2000\n",
      "Epoch 77/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8359 - accuracy: 0.5949 - val_loss: 1.4065 - val_accuracy: 0.2000\n",
      "Epoch 78/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.8334 - accuracy: 0.5949 - val_loss: 1.4133 - val_accuracy: 0.2000\n",
      "Epoch 79/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8309 - accuracy: 0.5949 - val_loss: 1.4203 - val_accuracy: 0.2000\n",
      "Epoch 80/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.8285 - accuracy: 0.5949 - val_loss: 1.4275 - val_accuracy: 0.2000\n",
      "Epoch 81/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8261 - accuracy: 0.5949 - val_loss: 1.4349 - val_accuracy: 0.2000\n",
      "Epoch 82/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.8237 - accuracy: 0.5949 - val_loss: 1.4425 - val_accuracy: 0.2000\n",
      "Epoch 83/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.8214 - accuracy: 0.5949 - val_loss: 1.4504 - val_accuracy: 0.2000\n",
      "Epoch 84/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.8190 - accuracy: 0.5949 - val_loss: 1.4584 - val_accuracy: 0.2000\n",
      "Epoch 85/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.8167 - accuracy: 0.6076 - val_loss: 1.4666 - val_accuracy: 0.2000\n",
      "Epoch 86/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8144 - accuracy: 0.6076 - val_loss: 1.4751 - val_accuracy: 0.2000\n",
      "Epoch 87/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.8122 - accuracy: 0.6076 - val_loss: 1.4838 - val_accuracy: 0.2000\n",
      "Epoch 88/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8099 - accuracy: 0.6076 - val_loss: 1.4928 - val_accuracy: 0.2000\n",
      "Epoch 89/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8077 - accuracy: 0.6076 - val_loss: 1.5021 - val_accuracy: 0.2000\n",
      "Epoch 90/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8054 - accuracy: 0.5949 - val_loss: 1.5117 - val_accuracy: 0.1500\n",
      "Epoch 91/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.8032 - accuracy: 0.5949 - val_loss: 1.5215 - val_accuracy: 0.1500\n",
      "Epoch 92/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8010 - accuracy: 0.5949 - val_loss: 1.5314 - val_accuracy: 0.1500\n",
      "Epoch 93/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.7989 - accuracy: 0.5949 - val_loss: 1.5415 - val_accuracy: 0.1500\n",
      "Epoch 94/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.7967 - accuracy: 0.5949 - val_loss: 1.5519 - val_accuracy: 0.1500\n",
      "Epoch 95/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7946 - accuracy: 0.5949 - val_loss: 1.5623 - val_accuracy: 0.1500\n",
      "Epoch 96/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7924 - accuracy: 0.5949 - val_loss: 1.5730 - val_accuracy: 0.1500\n",
      "Epoch 97/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7904 - accuracy: 0.5949 - val_loss: 1.5838 - val_accuracy: 0.1500\n",
      "Epoch 98/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7883 - accuracy: 0.5949 - val_loss: 1.5948 - val_accuracy: 0.1500\n",
      "Epoch 99/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7862 - accuracy: 0.5949 - val_loss: 1.6061 - val_accuracy: 0.1500\n",
      "Epoch 100/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.7842 - accuracy: 0.5949 - val_loss: 1.6175 - val_accuracy: 0.1500\n",
      "Epoch 101/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7822 - accuracy: 0.5823 - val_loss: 1.6291 - val_accuracy: 0.1500\n",
      "Epoch 102/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.7802 - accuracy: 0.5823 - val_loss: 1.6408 - val_accuracy: 0.1500\n",
      "Epoch 103/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7783 - accuracy: 0.5823 - val_loss: 1.6525 - val_accuracy: 0.1500\n",
      "Epoch 104/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7763 - accuracy: 0.5823 - val_loss: 1.6643 - val_accuracy: 0.1500\n",
      "Epoch 105/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7744 - accuracy: 0.5823 - val_loss: 1.6761 - val_accuracy: 0.1500\n",
      "Epoch 106/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.7725 - accuracy: 0.5823 - val_loss: 1.6878 - val_accuracy: 0.1500\n",
      "Epoch 107/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7706 - accuracy: 0.5949 - val_loss: 1.6996 - val_accuracy: 0.1500\n",
      "Epoch 108/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7688 - accuracy: 0.5949 - val_loss: 1.7115 - val_accuracy: 0.1500\n",
      "Epoch 109/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7670 - accuracy: 0.5949 - val_loss: 1.7236 - val_accuracy: 0.1500\n",
      "Epoch 110/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7651 - accuracy: 0.5949 - val_loss: 1.7358 - val_accuracy: 0.1500\n",
      "Epoch 111/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.7633 - accuracy: 0.5949 - val_loss: 1.7481 - val_accuracy: 0.1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.7615 - accuracy: 0.5949 - val_loss: 1.7605 - val_accuracy: 0.1500\n",
      "Epoch 113/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.7597 - accuracy: 0.5949 - val_loss: 1.7730 - val_accuracy: 0.1500\n",
      "Epoch 114/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.7579 - accuracy: 0.5949 - val_loss: 1.7855 - val_accuracy: 0.1500\n",
      "Epoch 115/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7561 - accuracy: 0.5949 - val_loss: 1.7981 - val_accuracy: 0.1500\n",
      "Epoch 116/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7544 - accuracy: 0.5949 - val_loss: 1.8107 - val_accuracy: 0.1500\n",
      "Epoch 117/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7526 - accuracy: 0.5949 - val_loss: 1.8233 - val_accuracy: 0.1500\n",
      "Epoch 118/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.7509 - accuracy: 0.5949 - val_loss: 1.8359 - val_accuracy: 0.1500\n",
      "Epoch 119/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7492 - accuracy: 0.5949 - val_loss: 1.8484 - val_accuracy: 0.1500\n",
      "Epoch 120/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.7475 - accuracy: 0.5949 - val_loss: 1.8611 - val_accuracy: 0.1500\n",
      "Epoch 121/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7459 - accuracy: 0.5949 - val_loss: 1.8739 - val_accuracy: 0.1500\n",
      "Epoch 122/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.7442 - accuracy: 0.5949 - val_loss: 1.8868 - val_accuracy: 0.1500\n",
      "Epoch 123/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7425 - accuracy: 0.5949 - val_loss: 1.8997 - val_accuracy: 0.1500\n",
      "Epoch 124/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.7408 - accuracy: 0.5949 - val_loss: 1.9129 - val_accuracy: 0.1500\n",
      "Epoch 125/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7392 - accuracy: 0.5949 - val_loss: 1.9261 - val_accuracy: 0.1500\n",
      "Epoch 126/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.7375 - accuracy: 0.5949 - val_loss: 1.9394 - val_accuracy: 0.1500\n",
      "Epoch 127/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7359 - accuracy: 0.5949 - val_loss: 1.9529 - val_accuracy: 0.1500\n",
      "Epoch 128/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7342 - accuracy: 0.5949 - val_loss: 1.9664 - val_accuracy: 0.1500\n",
      "Epoch 129/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7326 - accuracy: 0.5949 - val_loss: 1.9801 - val_accuracy: 0.1500\n",
      "Epoch 130/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.7310 - accuracy: 0.5949 - val_loss: 1.9936 - val_accuracy: 0.1500\n",
      "Epoch 131/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7295 - accuracy: 0.5949 - val_loss: 2.0071 - val_accuracy: 0.1500\n",
      "Epoch 132/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7280 - accuracy: 0.5949 - val_loss: 2.0207 - val_accuracy: 0.1500\n",
      "Epoch 133/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.7265 - accuracy: 0.6076 - val_loss: 2.0345 - val_accuracy: 0.1500\n",
      "Epoch 134/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7249 - accuracy: 0.6076 - val_loss: 2.0484 - val_accuracy: 0.1500\n",
      "Epoch 135/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.7234 - accuracy: 0.6076 - val_loss: 2.0623 - val_accuracy: 0.1500\n",
      "Epoch 136/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7219 - accuracy: 0.6076 - val_loss: 2.0762 - val_accuracy: 0.1500\n",
      "Epoch 137/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.7204 - accuracy: 0.6076 - val_loss: 2.0901 - val_accuracy: 0.1500\n",
      "Epoch 138/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7189 - accuracy: 0.6076 - val_loss: 2.1038 - val_accuracy: 0.1500\n",
      "Epoch 139/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7175 - accuracy: 0.6076 - val_loss: 2.1174 - val_accuracy: 0.1500\n",
      "Epoch 140/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7160 - accuracy: 0.6076 - val_loss: 2.1309 - val_accuracy: 0.1500\n",
      "Epoch 141/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.7145 - accuracy: 0.6076 - val_loss: 2.1444 - val_accuracy: 0.1500\n",
      "Epoch 142/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7131 - accuracy: 0.6076 - val_loss: 2.1580 - val_accuracy: 0.1500\n",
      "Epoch 143/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.7116 - accuracy: 0.6076 - val_loss: 2.1714 - val_accuracy: 0.1500\n",
      "Epoch 144/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.7102 - accuracy: 0.6076 - val_loss: 2.1849 - val_accuracy: 0.1500\n",
      "Epoch 145/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.7088 - accuracy: 0.6076 - val_loss: 2.1984 - val_accuracy: 0.1500\n",
      "Epoch 146/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7074 - accuracy: 0.6076 - val_loss: 2.2119 - val_accuracy: 0.1500\n",
      "Epoch 147/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.7060 - accuracy: 0.6203 - val_loss: 2.2255 - val_accuracy: 0.1500\n",
      "Epoch 148/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7046 - accuracy: 0.6203 - val_loss: 2.2392 - val_accuracy: 0.1500\n",
      "Epoch 149/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7032 - accuracy: 0.6203 - val_loss: 2.2528 - val_accuracy: 0.1500\n",
      "Epoch 150/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.7018 - accuracy: 0.6203 - val_loss: 2.2665 - val_accuracy: 0.1500\n",
      "Epoch 151/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.7004 - accuracy: 0.6329 - val_loss: 2.2802 - val_accuracy: 0.1500\n",
      "Epoch 152/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6990 - accuracy: 0.6456 - val_loss: 2.2940 - val_accuracy: 0.1500\n",
      "Epoch 153/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6976 - accuracy: 0.6456 - val_loss: 2.3078 - val_accuracy: 0.1500\n",
      "Epoch 154/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.6962 - accuracy: 0.6456 - val_loss: 2.3215 - val_accuracy: 0.1500\n",
      "Epoch 155/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.6948 - accuracy: 0.6456 - val_loss: 2.3352 - val_accuracy: 0.1500\n",
      "Epoch 156/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6934 - accuracy: 0.6456 - val_loss: 2.3490 - val_accuracy: 0.1500\n",
      "Epoch 157/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6920 - accuracy: 0.6582 - val_loss: 2.3628 - val_accuracy: 0.1500\n",
      "Epoch 158/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6905 - accuracy: 0.6709 - val_loss: 2.3764 - val_accuracy: 0.1500\n",
      "Epoch 159/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6891 - accuracy: 0.6709 - val_loss: 2.3898 - val_accuracy: 0.1500\n",
      "Epoch 160/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.6877 - accuracy: 0.6709 - val_loss: 2.4033 - val_accuracy: 0.1500\n",
      "Epoch 161/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.6863 - accuracy: 0.6709 - val_loss: 2.4168 - val_accuracy: 0.1500\n",
      "Epoch 162/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6850 - accuracy: 0.6709 - val_loss: 2.4303 - val_accuracy: 0.1500\n",
      "Epoch 163/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6836 - accuracy: 0.6709 - val_loss: 2.4436 - val_accuracy: 0.1500\n",
      "Epoch 164/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6823 - accuracy: 0.6709 - val_loss: 2.4569 - val_accuracy: 0.1500\n",
      "Epoch 165/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.6809 - accuracy: 0.6709 - val_loss: 2.4700 - val_accuracy: 0.1500\n",
      "Epoch 166/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.6796 - accuracy: 0.6582 - val_loss: 2.4830 - val_accuracy: 0.1500\n",
      "Epoch 167/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6782 - accuracy: 0.6582 - val_loss: 2.4959 - val_accuracy: 0.1500\n",
      "Epoch 168/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6768 - accuracy: 0.6582 - val_loss: 2.5088 - val_accuracy: 0.1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.6755 - accuracy: 0.6582 - val_loss: 2.5216 - val_accuracy: 0.1500\n",
      "Epoch 170/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.6742 - accuracy: 0.6582 - val_loss: 2.5345 - val_accuracy: 0.1500\n",
      "Epoch 171/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6728 - accuracy: 0.6582 - val_loss: 2.5474 - val_accuracy: 0.1500\n",
      "Epoch 172/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.6715 - accuracy: 0.6582 - val_loss: 2.5605 - val_accuracy: 0.1500\n",
      "Epoch 173/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6701 - accuracy: 0.6582 - val_loss: 2.5734 - val_accuracy: 0.1500\n",
      "Epoch 174/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6688 - accuracy: 0.6582 - val_loss: 2.5862 - val_accuracy: 0.1500\n",
      "Epoch 175/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6674 - accuracy: 0.6582 - val_loss: 2.5989 - val_accuracy: 0.1500\n",
      "Epoch 176/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6660 - accuracy: 0.6582 - val_loss: 2.6116 - val_accuracy: 0.1500\n",
      "Epoch 177/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.6647 - accuracy: 0.6582 - val_loss: 2.6243 - val_accuracy: 0.1500\n",
      "Epoch 178/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6633 - accuracy: 0.6582 - val_loss: 2.6369 - val_accuracy: 0.1500\n",
      "Epoch 179/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6620 - accuracy: 0.6582 - val_loss: 2.6495 - val_accuracy: 0.1500\n",
      "Epoch 180/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6607 - accuracy: 0.6582 - val_loss: 2.6621 - val_accuracy: 0.1500\n",
      "Epoch 181/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6594 - accuracy: 0.6582 - val_loss: 2.6746 - val_accuracy: 0.1500\n",
      "Epoch 182/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6581 - accuracy: 0.6582 - val_loss: 2.6872 - val_accuracy: 0.1500\n",
      "Epoch 183/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.6568 - accuracy: 0.6582 - val_loss: 2.6996 - val_accuracy: 0.1500\n",
      "Epoch 184/500\n",
      "79/79 [==============================] - 0s 50us/step - loss: 0.6555 - accuracy: 0.6582 - val_loss: 2.7120 - val_accuracy: 0.1500\n",
      "Epoch 185/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6541 - accuracy: 0.6582 - val_loss: 2.7242 - val_accuracy: 0.1500\n",
      "Epoch 186/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6528 - accuracy: 0.6582 - val_loss: 2.7365 - val_accuracy: 0.1500\n",
      "Epoch 187/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.6515 - accuracy: 0.6582 - val_loss: 2.7490 - val_accuracy: 0.1500\n",
      "Epoch 188/500\n",
      "79/79 [==============================] - 0s 37us/step - loss: 0.6502 - accuracy: 0.6582 - val_loss: 2.7614 - val_accuracy: 0.1500\n",
      "Epoch 189/500\n",
      "79/79 [==============================] - 0s 50us/step - loss: 0.6489 - accuracy: 0.6582 - val_loss: 2.7739 - val_accuracy: 0.1500\n",
      "Epoch 190/500\n",
      "79/79 [==============================] - 0s 51us/step - loss: 0.6476 - accuracy: 0.6582 - val_loss: 2.7864 - val_accuracy: 0.1500\n",
      "Epoch 191/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.6462 - accuracy: 0.6582 - val_loss: 2.7989 - val_accuracy: 0.1500\n",
      "Epoch 192/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6449 - accuracy: 0.6582 - val_loss: 2.8113 - val_accuracy: 0.1500\n",
      "Epoch 193/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.6436 - accuracy: 0.6835 - val_loss: 2.8236 - val_accuracy: 0.1500\n",
      "Epoch 194/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.6422 - accuracy: 0.6835 - val_loss: 2.8358 - val_accuracy: 0.1500\n",
      "Epoch 195/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.6409 - accuracy: 0.6835 - val_loss: 2.8479 - val_accuracy: 0.1500\n",
      "Epoch 196/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6395 - accuracy: 0.6835 - val_loss: 2.8602 - val_accuracy: 0.1500\n",
      "Epoch 197/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.6382 - accuracy: 0.6835 - val_loss: 2.8727 - val_accuracy: 0.1500\n",
      "Epoch 198/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.6368 - accuracy: 0.6835 - val_loss: 2.8853 - val_accuracy: 0.1500\n",
      "Epoch 199/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.6355 - accuracy: 0.6835 - val_loss: 2.8980 - val_accuracy: 0.1500\n",
      "Epoch 200/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.6341 - accuracy: 0.6835 - val_loss: 2.9105 - val_accuracy: 0.1500\n",
      "Epoch 201/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6327 - accuracy: 0.6962 - val_loss: 2.9231 - val_accuracy: 0.1500\n",
      "Epoch 202/500\n",
      "79/79 [==============================] - 0s 50us/step - loss: 0.6314 - accuracy: 0.6962 - val_loss: 2.9357 - val_accuracy: 0.1500\n",
      "Epoch 203/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6300 - accuracy: 0.6962 - val_loss: 2.9484 - val_accuracy: 0.1500\n",
      "Epoch 204/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.6286 - accuracy: 0.6962 - val_loss: 2.9609 - val_accuracy: 0.1500\n",
      "Epoch 205/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.6273 - accuracy: 0.6962 - val_loss: 2.9733 - val_accuracy: 0.1500\n",
      "Epoch 206/500\n",
      "79/79 [==============================] - 0s 50us/step - loss: 0.6259 - accuracy: 0.6962 - val_loss: 2.9858 - val_accuracy: 0.1500\n",
      "Epoch 207/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6246 - accuracy: 0.6962 - val_loss: 2.9984 - val_accuracy: 0.1500\n",
      "Epoch 208/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6232 - accuracy: 0.7089 - val_loss: 3.0114 - val_accuracy: 0.1500\n",
      "Epoch 209/500\n",
      "79/79 [==============================] - 0s 51us/step - loss: 0.6219 - accuracy: 0.7089 - val_loss: 3.0246 - val_accuracy: 0.1500\n",
      "Epoch 210/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6206 - accuracy: 0.7089 - val_loss: 3.0377 - val_accuracy: 0.1500\n",
      "Epoch 211/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.6193 - accuracy: 0.7089 - val_loss: 3.0510 - val_accuracy: 0.1500\n",
      "Epoch 212/500\n",
      "79/79 [==============================] - 0s 50us/step - loss: 0.6179 - accuracy: 0.7089 - val_loss: 3.0643 - val_accuracy: 0.1500\n",
      "Epoch 213/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6166 - accuracy: 0.7089 - val_loss: 3.0778 - val_accuracy: 0.1500\n",
      "Epoch 214/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6152 - accuracy: 0.7089 - val_loss: 3.0916 - val_accuracy: 0.1500\n",
      "Epoch 215/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.6139 - accuracy: 0.7089 - val_loss: 3.1055 - val_accuracy: 0.1500\n",
      "Epoch 216/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6126 - accuracy: 0.7089 - val_loss: 3.1192 - val_accuracy: 0.1500\n",
      "Epoch 217/500\n",
      "79/79 [==============================] - 0s 51us/step - loss: 0.6112 - accuracy: 0.7089 - val_loss: 3.1327 - val_accuracy: 0.1500\n",
      "Epoch 218/500\n",
      "79/79 [==============================] - 0s 37us/step - loss: 0.6099 - accuracy: 0.7342 - val_loss: 3.1461 - val_accuracy: 0.1500\n",
      "Epoch 219/500\n",
      "79/79 [==============================] - 0s 51us/step - loss: 0.6086 - accuracy: 0.7342 - val_loss: 3.1594 - val_accuracy: 0.1500\n",
      "Epoch 220/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.6073 - accuracy: 0.7342 - val_loss: 3.1727 - val_accuracy: 0.1500\n",
      "Epoch 221/500\n",
      "79/79 [==============================] - 0s 50us/step - loss: 0.6059 - accuracy: 0.7342 - val_loss: 3.1861 - val_accuracy: 0.1500\n",
      "Epoch 222/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6046 - accuracy: 0.7342 - val_loss: 3.1994 - val_accuracy: 0.1500\n",
      "Epoch 223/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.6033 - accuracy: 0.7468 - val_loss: 3.2128 - val_accuracy: 0.1500\n",
      "Epoch 224/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.6019 - accuracy: 0.7468 - val_loss: 3.2263 - val_accuracy: 0.1500\n",
      "Epoch 225/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.6006 - accuracy: 0.7468 - val_loss: 3.2399 - val_accuracy: 0.1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5992 - accuracy: 0.7468 - val_loss: 3.2537 - val_accuracy: 0.1500\n",
      "Epoch 227/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5979 - accuracy: 0.7468 - val_loss: 3.2677 - val_accuracy: 0.1500\n",
      "Epoch 228/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5966 - accuracy: 0.7468 - val_loss: 3.2822 - val_accuracy: 0.1500\n",
      "Epoch 229/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5952 - accuracy: 0.7468 - val_loss: 3.2970 - val_accuracy: 0.1500\n",
      "Epoch 230/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5939 - accuracy: 0.7468 - val_loss: 3.3122 - val_accuracy: 0.1500\n",
      "Epoch 231/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5926 - accuracy: 0.7468 - val_loss: 3.3274 - val_accuracy: 0.1500\n",
      "Epoch 232/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5912 - accuracy: 0.7468 - val_loss: 3.3427 - val_accuracy: 0.1500\n",
      "Epoch 233/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5899 - accuracy: 0.7468 - val_loss: 3.3580 - val_accuracy: 0.1500\n",
      "Epoch 234/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5886 - accuracy: 0.7468 - val_loss: 3.3736 - val_accuracy: 0.1500\n",
      "Epoch 235/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5873 - accuracy: 0.7595 - val_loss: 3.3894 - val_accuracy: 0.1500\n",
      "Epoch 236/500\n",
      "79/79 [==============================] - 0s 50us/step - loss: 0.5859 - accuracy: 0.7595 - val_loss: 3.4055 - val_accuracy: 0.1500\n",
      "Epoch 237/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5846 - accuracy: 0.7595 - val_loss: 3.4218 - val_accuracy: 0.1500\n",
      "Epoch 238/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5833 - accuracy: 0.7595 - val_loss: 3.4383 - val_accuracy: 0.1500\n",
      "Epoch 239/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5820 - accuracy: 0.7595 - val_loss: 3.4550 - val_accuracy: 0.1500\n",
      "Epoch 240/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5807 - accuracy: 0.7595 - val_loss: 3.4716 - val_accuracy: 0.1500\n",
      "Epoch 241/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5794 - accuracy: 0.7595 - val_loss: 3.4884 - val_accuracy: 0.1500\n",
      "Epoch 242/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5782 - accuracy: 0.7722 - val_loss: 3.5054 - val_accuracy: 0.1500\n",
      "Epoch 243/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5769 - accuracy: 0.7722 - val_loss: 3.5225 - val_accuracy: 0.1500\n",
      "Epoch 244/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.5756 - accuracy: 0.7722 - val_loss: 3.5397 - val_accuracy: 0.1500\n",
      "Epoch 245/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5743 - accuracy: 0.7722 - val_loss: 3.5569 - val_accuracy: 0.1500\n",
      "Epoch 246/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5730 - accuracy: 0.7722 - val_loss: 3.5744 - val_accuracy: 0.1500\n",
      "Epoch 247/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5718 - accuracy: 0.7848 - val_loss: 3.5922 - val_accuracy: 0.1500\n",
      "Epoch 248/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5705 - accuracy: 0.7848 - val_loss: 3.6101 - val_accuracy: 0.1500\n",
      "Epoch 249/500\n",
      "79/79 [==============================] - 0s 50us/step - loss: 0.5693 - accuracy: 0.8101 - val_loss: 3.6278 - val_accuracy: 0.1500\n",
      "Epoch 250/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5680 - accuracy: 0.8101 - val_loss: 3.6454 - val_accuracy: 0.1500\n",
      "Epoch 251/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5668 - accuracy: 0.8101 - val_loss: 3.6626 - val_accuracy: 0.1500\n",
      "Epoch 252/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5655 - accuracy: 0.8101 - val_loss: 3.6796 - val_accuracy: 0.1500\n",
      "Epoch 253/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5643 - accuracy: 0.8101 - val_loss: 3.6966 - val_accuracy: 0.1500\n",
      "Epoch 254/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5631 - accuracy: 0.8101 - val_loss: 3.7136 - val_accuracy: 0.1500\n",
      "Epoch 255/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5618 - accuracy: 0.8101 - val_loss: 3.7302 - val_accuracy: 0.1500\n",
      "Epoch 256/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5606 - accuracy: 0.8101 - val_loss: 3.7467 - val_accuracy: 0.1500\n",
      "Epoch 257/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5594 - accuracy: 0.8101 - val_loss: 3.7632 - val_accuracy: 0.1500\n",
      "Epoch 258/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5582 - accuracy: 0.8101 - val_loss: 3.7798 - val_accuracy: 0.1500\n",
      "Epoch 259/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.5569 - accuracy: 0.8101 - val_loss: 3.7963 - val_accuracy: 0.1500\n",
      "Epoch 260/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5557 - accuracy: 0.8101 - val_loss: 3.8128 - val_accuracy: 0.1500\n",
      "Epoch 261/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5545 - accuracy: 0.8101 - val_loss: 3.8295 - val_accuracy: 0.1500\n",
      "Epoch 262/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5533 - accuracy: 0.8101 - val_loss: 3.8464 - val_accuracy: 0.1500\n",
      "Epoch 263/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5521 - accuracy: 0.8101 - val_loss: 3.8633 - val_accuracy: 0.1500\n",
      "Epoch 264/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5509 - accuracy: 0.8101 - val_loss: 3.8801 - val_accuracy: 0.1500\n",
      "Epoch 265/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5497 - accuracy: 0.8101 - val_loss: 3.8971 - val_accuracy: 0.1500\n",
      "Epoch 266/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5486 - accuracy: 0.8101 - val_loss: 3.9144 - val_accuracy: 0.1500\n",
      "Epoch 267/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5474 - accuracy: 0.8101 - val_loss: 3.9319 - val_accuracy: 0.1500\n",
      "Epoch 268/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5462 - accuracy: 0.8101 - val_loss: 3.9498 - val_accuracy: 0.1500\n",
      "Epoch 269/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.5450 - accuracy: 0.8101 - val_loss: 3.9676 - val_accuracy: 0.1500\n",
      "Epoch 270/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5438 - accuracy: 0.8101 - val_loss: 3.9853 - val_accuracy: 0.1500\n",
      "Epoch 271/500\n",
      "79/79 [==============================] - 0s 51us/step - loss: 0.5427 - accuracy: 0.8101 - val_loss: 4.0028 - val_accuracy: 0.1500\n",
      "Epoch 272/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5415 - accuracy: 0.8101 - val_loss: 4.0200 - val_accuracy: 0.1500\n",
      "Epoch 273/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.5404 - accuracy: 0.8101 - val_loss: 4.0375 - val_accuracy: 0.1500\n",
      "Epoch 274/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5393 - accuracy: 0.8101 - val_loss: 4.0552 - val_accuracy: 0.1500\n",
      "Epoch 275/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5381 - accuracy: 0.8101 - val_loss: 4.0729 - val_accuracy: 0.1500\n",
      "Epoch 276/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5370 - accuracy: 0.8101 - val_loss: 4.0907 - val_accuracy: 0.1500\n",
      "Epoch 277/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5358 - accuracy: 0.8101 - val_loss: 4.1090 - val_accuracy: 0.1500\n",
      "Epoch 278/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.5347 - accuracy: 0.8101 - val_loss: 4.1273 - val_accuracy: 0.1500\n",
      "Epoch 279/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5336 - accuracy: 0.8228 - val_loss: 4.1454 - val_accuracy: 0.1500\n",
      "Epoch 280/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5324 - accuracy: 0.8228 - val_loss: 4.1635 - val_accuracy: 0.1500\n",
      "Epoch 281/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5313 - accuracy: 0.8354 - val_loss: 4.1814 - val_accuracy: 0.1500\n",
      "Epoch 282/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5302 - accuracy: 0.8354 - val_loss: 4.1993 - val_accuracy: 0.1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.5290 - accuracy: 0.8354 - val_loss: 4.2173 - val_accuracy: 0.1500\n",
      "Epoch 284/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5279 - accuracy: 0.8354 - val_loss: 4.2351 - val_accuracy: 0.1500\n",
      "Epoch 285/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.5268 - accuracy: 0.8354 - val_loss: 4.2531 - val_accuracy: 0.1500\n",
      "Epoch 286/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5256 - accuracy: 0.8354 - val_loss: 4.2709 - val_accuracy: 0.1500\n",
      "Epoch 287/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5245 - accuracy: 0.8354 - val_loss: 4.2887 - val_accuracy: 0.1500\n",
      "Epoch 288/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5234 - accuracy: 0.8354 - val_loss: 4.3066 - val_accuracy: 0.1500\n",
      "Epoch 289/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.5222 - accuracy: 0.8354 - val_loss: 4.3248 - val_accuracy: 0.1500\n",
      "Epoch 290/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5211 - accuracy: 0.8354 - val_loss: 4.3432 - val_accuracy: 0.1500\n",
      "Epoch 291/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5199 - accuracy: 0.8354 - val_loss: 4.3620 - val_accuracy: 0.1500\n",
      "Epoch 292/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5188 - accuracy: 0.8354 - val_loss: 4.3806 - val_accuracy: 0.1500\n",
      "Epoch 293/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5177 - accuracy: 0.8354 - val_loss: 4.3989 - val_accuracy: 0.1500\n",
      "Epoch 294/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.5166 - accuracy: 0.8354 - val_loss: 4.4169 - val_accuracy: 0.1500\n",
      "Epoch 295/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5155 - accuracy: 0.8354 - val_loss: 4.4343 - val_accuracy: 0.1500\n",
      "Epoch 296/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5144 - accuracy: 0.8354 - val_loss: 4.4517 - val_accuracy: 0.1500\n",
      "Epoch 297/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5134 - accuracy: 0.8354 - val_loss: 4.4690 - val_accuracy: 0.1500\n",
      "Epoch 298/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5123 - accuracy: 0.8354 - val_loss: 4.4864 - val_accuracy: 0.1500\n",
      "Epoch 299/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5112 - accuracy: 0.8354 - val_loss: 4.5038 - val_accuracy: 0.1500\n",
      "Epoch 300/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.5101 - accuracy: 0.8354 - val_loss: 4.5213 - val_accuracy: 0.1500\n",
      "Epoch 301/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5090 - accuracy: 0.8354 - val_loss: 4.5387 - val_accuracy: 0.1500\n",
      "Epoch 302/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5079 - accuracy: 0.8354 - val_loss: 4.5558 - val_accuracy: 0.1500\n",
      "Epoch 303/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5068 - accuracy: 0.8354 - val_loss: 4.5724 - val_accuracy: 0.1500\n",
      "Epoch 304/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5057 - accuracy: 0.8354 - val_loss: 4.5888 - val_accuracy: 0.1500\n",
      "Epoch 305/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5046 - accuracy: 0.8354 - val_loss: 4.6051 - val_accuracy: 0.1500\n",
      "Epoch 306/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.5035 - accuracy: 0.8354 - val_loss: 4.6217 - val_accuracy: 0.1500\n",
      "Epoch 307/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5024 - accuracy: 0.8354 - val_loss: 4.6381 - val_accuracy: 0.1500\n",
      "Epoch 308/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5013 - accuracy: 0.8354 - val_loss: 4.6544 - val_accuracy: 0.1500\n",
      "Epoch 309/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.5002 - accuracy: 0.8354 - val_loss: 4.6708 - val_accuracy: 0.1500\n",
      "Epoch 310/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.4991 - accuracy: 0.8354 - val_loss: 4.6880 - val_accuracy: 0.1500\n",
      "Epoch 311/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4981 - accuracy: 0.8354 - val_loss: 4.7053 - val_accuracy: 0.1500\n",
      "Epoch 312/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4970 - accuracy: 0.8354 - val_loss: 4.7231 - val_accuracy: 0.1500\n",
      "Epoch 313/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4960 - accuracy: 0.8354 - val_loss: 4.7409 - val_accuracy: 0.1500\n",
      "Epoch 314/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.4949 - accuracy: 0.8354 - val_loss: 4.7586 - val_accuracy: 0.1500\n",
      "Epoch 315/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4939 - accuracy: 0.8354 - val_loss: 4.7764 - val_accuracy: 0.1500\n",
      "Epoch 316/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4928 - accuracy: 0.8354 - val_loss: 4.7944 - val_accuracy: 0.1500\n",
      "Epoch 317/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.4917 - accuracy: 0.8354 - val_loss: 4.8129 - val_accuracy: 0.1500\n",
      "Epoch 318/500\n",
      "79/79 [==============================] - 0s 50us/step - loss: 0.4907 - accuracy: 0.8354 - val_loss: 4.8320 - val_accuracy: 0.1500\n",
      "Epoch 319/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4897 - accuracy: 0.8354 - val_loss: 4.8514 - val_accuracy: 0.1500\n",
      "Epoch 320/500\n",
      "79/79 [==============================] - 0s 37us/step - loss: 0.4886 - accuracy: 0.8354 - val_loss: 4.8710 - val_accuracy: 0.1500\n",
      "Epoch 321/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4876 - accuracy: 0.8354 - val_loss: 4.8904 - val_accuracy: 0.1500\n",
      "Epoch 322/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4865 - accuracy: 0.8354 - val_loss: 4.9097 - val_accuracy: 0.1500\n",
      "Epoch 323/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4855 - accuracy: 0.8481 - val_loss: 4.9291 - val_accuracy: 0.1500\n",
      "Epoch 324/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4845 - accuracy: 0.8481 - val_loss: 4.9483 - val_accuracy: 0.1500\n",
      "Epoch 325/500\n",
      "79/79 [==============================] - 0s 51us/step - loss: 0.4834 - accuracy: 0.8481 - val_loss: 4.9678 - val_accuracy: 0.1500\n",
      "Epoch 326/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4824 - accuracy: 0.8481 - val_loss: 4.9873 - val_accuracy: 0.1500\n",
      "Epoch 327/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4814 - accuracy: 0.8481 - val_loss: 5.0071 - val_accuracy: 0.1500\n",
      "Epoch 328/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4804 - accuracy: 0.8481 - val_loss: 5.0273 - val_accuracy: 0.1500\n",
      "Epoch 329/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4793 - accuracy: 0.8481 - val_loss: 5.0480 - val_accuracy: 0.1500\n",
      "Epoch 330/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4783 - accuracy: 0.8481 - val_loss: 5.0691 - val_accuracy: 0.1500\n",
      "Epoch 331/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4773 - accuracy: 0.8481 - val_loss: 5.0899 - val_accuracy: 0.1500\n",
      "Epoch 332/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4763 - accuracy: 0.8481 - val_loss: 5.1107 - val_accuracy: 0.1500\n",
      "Epoch 333/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4753 - accuracy: 0.8481 - val_loss: 5.1312 - val_accuracy: 0.1500\n",
      "Epoch 334/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4743 - accuracy: 0.8481 - val_loss: 5.1519 - val_accuracy: 0.1500\n",
      "Epoch 335/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.4733 - accuracy: 0.8481 - val_loss: 5.1731 - val_accuracy: 0.1500\n",
      "Epoch 336/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.4723 - accuracy: 0.8481 - val_loss: 5.1946 - val_accuracy: 0.1500\n",
      "Epoch 337/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4712 - accuracy: 0.8481 - val_loss: 5.2164 - val_accuracy: 0.1500\n",
      "Epoch 338/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.4702 - accuracy: 0.8481 - val_loss: 5.2380 - val_accuracy: 0.1500\n",
      "Epoch 339/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.4692 - accuracy: 0.8481 - val_loss: 5.2592 - val_accuracy: 0.1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 340/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4682 - accuracy: 0.8481 - val_loss: 5.2803 - val_accuracy: 0.1500\n",
      "Epoch 341/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4671 - accuracy: 0.8481 - val_loss: 5.3014 - val_accuracy: 0.1500\n",
      "Epoch 342/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4661 - accuracy: 0.8481 - val_loss: 5.3226 - val_accuracy: 0.1500\n",
      "Epoch 343/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.4651 - accuracy: 0.8481 - val_loss: 5.3433 - val_accuracy: 0.1500\n",
      "Epoch 344/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4640 - accuracy: 0.8481 - val_loss: 5.3641 - val_accuracy: 0.1500\n",
      "Epoch 345/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4630 - accuracy: 0.8481 - val_loss: 5.3846 - val_accuracy: 0.1500\n",
      "Epoch 346/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4620 - accuracy: 0.8481 - val_loss: 5.4052 - val_accuracy: 0.1500\n",
      "Epoch 347/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4609 - accuracy: 0.8481 - val_loss: 5.4255 - val_accuracy: 0.1500\n",
      "Epoch 348/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4599 - accuracy: 0.8481 - val_loss: 5.4456 - val_accuracy: 0.1500\n",
      "Epoch 349/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.4589 - accuracy: 0.8481 - val_loss: 5.4658 - val_accuracy: 0.1500\n",
      "Epoch 350/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4578 - accuracy: 0.8481 - val_loss: 5.4858 - val_accuracy: 0.1500\n",
      "Epoch 351/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4568 - accuracy: 0.8481 - val_loss: 5.5063 - val_accuracy: 0.1500\n",
      "Epoch 352/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4557 - accuracy: 0.8481 - val_loss: 5.5270 - val_accuracy: 0.1500\n",
      "Epoch 353/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.4547 - accuracy: 0.8481 - val_loss: 5.5480 - val_accuracy: 0.1500\n",
      "Epoch 354/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4536 - accuracy: 0.8481 - val_loss: 5.5689 - val_accuracy: 0.1500\n",
      "Epoch 355/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4526 - accuracy: 0.8481 - val_loss: 5.5900 - val_accuracy: 0.1500\n",
      "Epoch 356/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4516 - accuracy: 0.8481 - val_loss: 5.6116 - val_accuracy: 0.1500\n",
      "Epoch 357/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4506 - accuracy: 0.8481 - val_loss: 5.6326 - val_accuracy: 0.1500\n",
      "Epoch 358/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4495 - accuracy: 0.8481 - val_loss: 5.6532 - val_accuracy: 0.1500\n",
      "Epoch 359/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4485 - accuracy: 0.8481 - val_loss: 5.6742 - val_accuracy: 0.1500\n",
      "Epoch 360/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.4475 - accuracy: 0.8481 - val_loss: 5.6957 - val_accuracy: 0.1500\n",
      "Epoch 361/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.4465 - accuracy: 0.8481 - val_loss: 5.7172 - val_accuracy: 0.1500\n",
      "Epoch 362/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4455 - accuracy: 0.8481 - val_loss: 5.7393 - val_accuracy: 0.1500\n",
      "Epoch 363/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4446 - accuracy: 0.8481 - val_loss: 5.7613 - val_accuracy: 0.1500\n",
      "Epoch 364/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4436 - accuracy: 0.8608 - val_loss: 5.7838 - val_accuracy: 0.1500\n",
      "Epoch 365/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.4426 - accuracy: 0.8608 - val_loss: 5.8062 - val_accuracy: 0.1500\n",
      "Epoch 366/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.4416 - accuracy: 0.8608 - val_loss: 5.8285 - val_accuracy: 0.1500\n",
      "Epoch 367/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4407 - accuracy: 0.8608 - val_loss: 5.8510 - val_accuracy: 0.1500\n",
      "Epoch 368/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4398 - accuracy: 0.8608 - val_loss: 5.8733 - val_accuracy: 0.1500\n",
      "Epoch 369/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.4388 - accuracy: 0.8608 - val_loss: 5.8958 - val_accuracy: 0.1500\n",
      "Epoch 370/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4379 - accuracy: 0.8608 - val_loss: 5.9187 - val_accuracy: 0.1500\n",
      "Epoch 371/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4369 - accuracy: 0.8608 - val_loss: 5.9419 - val_accuracy: 0.1500\n",
      "Epoch 372/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4360 - accuracy: 0.8608 - val_loss: 5.9653 - val_accuracy: 0.1500\n",
      "Epoch 373/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.4351 - accuracy: 0.8608 - val_loss: 5.9884 - val_accuracy: 0.1500\n",
      "Epoch 374/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.4342 - accuracy: 0.8608 - val_loss: 6.0113 - val_accuracy: 0.1500\n",
      "Epoch 375/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4333 - accuracy: 0.8608 - val_loss: 6.0344 - val_accuracy: 0.1500\n",
      "Epoch 376/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.4324 - accuracy: 0.8608 - val_loss: 6.0576 - val_accuracy: 0.1500\n",
      "Epoch 377/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4315 - accuracy: 0.8608 - val_loss: 6.0813 - val_accuracy: 0.1500\n",
      "Epoch 378/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4306 - accuracy: 0.8608 - val_loss: 6.1047 - val_accuracy: 0.1500\n",
      "Epoch 379/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4298 - accuracy: 0.8608 - val_loss: 6.1280 - val_accuracy: 0.1500\n",
      "Epoch 380/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4289 - accuracy: 0.8608 - val_loss: 6.1515 - val_accuracy: 0.1500\n",
      "Epoch 381/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.4280 - accuracy: 0.8608 - val_loss: 6.1751 - val_accuracy: 0.1500\n",
      "Epoch 382/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4271 - accuracy: 0.8608 - val_loss: 6.1984 - val_accuracy: 0.1500\n",
      "Epoch 383/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4263 - accuracy: 0.8608 - val_loss: 6.2212 - val_accuracy: 0.1500\n",
      "Epoch 384/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.4254 - accuracy: 0.8608 - val_loss: 6.2441 - val_accuracy: 0.1500\n",
      "Epoch 385/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4246 - accuracy: 0.8608 - val_loss: 6.2669 - val_accuracy: 0.1500\n",
      "Epoch 386/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4237 - accuracy: 0.8608 - val_loss: 6.2892 - val_accuracy: 0.1500\n",
      "Epoch 387/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.4229 - accuracy: 0.8608 - val_loss: 6.3120 - val_accuracy: 0.1500\n",
      "Epoch 388/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4221 - accuracy: 0.8608 - val_loss: 6.3348 - val_accuracy: 0.1500\n",
      "Epoch 389/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.4213 - accuracy: 0.8608 - val_loss: 6.3572 - val_accuracy: 0.1500\n",
      "Epoch 390/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4204 - accuracy: 0.8608 - val_loss: 6.3792 - val_accuracy: 0.1500\n",
      "Epoch 391/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4196 - accuracy: 0.8608 - val_loss: 6.4010 - val_accuracy: 0.1500\n",
      "Epoch 392/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4188 - accuracy: 0.8608 - val_loss: 6.4229 - val_accuracy: 0.1500\n",
      "Epoch 393/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4180 - accuracy: 0.8608 - val_loss: 6.4447 - val_accuracy: 0.1500\n",
      "Epoch 394/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4172 - accuracy: 0.8608 - val_loss: 6.4664 - val_accuracy: 0.1500\n",
      "Epoch 395/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.4164 - accuracy: 0.8608 - val_loss: 6.4883 - val_accuracy: 0.1500\n",
      "Epoch 396/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4156 - accuracy: 0.8608 - val_loss: 6.5100 - val_accuracy: 0.1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 397/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4148 - accuracy: 0.8608 - val_loss: 6.5311 - val_accuracy: 0.1500\n",
      "Epoch 398/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.4140 - accuracy: 0.8608 - val_loss: 6.5521 - val_accuracy: 0.1500\n",
      "Epoch 399/500\n",
      "79/79 [==============================] - 0s 37us/step - loss: 0.4132 - accuracy: 0.8608 - val_loss: 6.5727 - val_accuracy: 0.1500\n",
      "Epoch 400/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4124 - accuracy: 0.8608 - val_loss: 6.5934 - val_accuracy: 0.1500\n",
      "Epoch 401/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4116 - accuracy: 0.8608 - val_loss: 6.6145 - val_accuracy: 0.1500\n",
      "Epoch 402/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4108 - accuracy: 0.8608 - val_loss: 6.6355 - val_accuracy: 0.1500\n",
      "Epoch 403/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4100 - accuracy: 0.8608 - val_loss: 6.6559 - val_accuracy: 0.1500\n",
      "Epoch 404/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4093 - accuracy: 0.8608 - val_loss: 6.6741 - val_accuracy: 0.1500\n",
      "Epoch 405/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4085 - accuracy: 0.8608 - val_loss: 6.6921 - val_accuracy: 0.1500\n",
      "Epoch 406/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4076 - accuracy: 0.8608 - val_loss: 6.7098 - val_accuracy: 0.1500\n",
      "Epoch 407/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4069 - accuracy: 0.8608 - val_loss: 6.7278 - val_accuracy: 0.1500\n",
      "Epoch 408/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4061 - accuracy: 0.8608 - val_loss: 6.7457 - val_accuracy: 0.1500\n",
      "Epoch 409/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4053 - accuracy: 0.8608 - val_loss: 6.7639 - val_accuracy: 0.1500\n",
      "Epoch 410/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4046 - accuracy: 0.8608 - val_loss: 6.7819 - val_accuracy: 0.1500\n",
      "Epoch 411/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4038 - accuracy: 0.8608 - val_loss: 6.7995 - val_accuracy: 0.1500\n",
      "Epoch 412/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4030 - accuracy: 0.8608 - val_loss: 6.8173 - val_accuracy: 0.1500\n",
      "Epoch 413/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4023 - accuracy: 0.8608 - val_loss: 6.8358 - val_accuracy: 0.1500\n",
      "Epoch 414/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4015 - accuracy: 0.8608 - val_loss: 6.8546 - val_accuracy: 0.1500\n",
      "Epoch 415/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4008 - accuracy: 0.8608 - val_loss: 6.8738 - val_accuracy: 0.1500\n",
      "Epoch 416/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4000 - accuracy: 0.8608 - val_loss: 6.8930 - val_accuracy: 0.1500\n",
      "Epoch 417/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.3992 - accuracy: 0.8608 - val_loss: 6.9120 - val_accuracy: 0.1500\n",
      "Epoch 418/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.3985 - accuracy: 0.8608 - val_loss: 6.9308 - val_accuracy: 0.1500\n",
      "Epoch 419/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3977 - accuracy: 0.8608 - val_loss: 6.9497 - val_accuracy: 0.1500\n",
      "Epoch 420/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.3970 - accuracy: 0.8608 - val_loss: 6.9683 - val_accuracy: 0.1500\n",
      "Epoch 421/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.3962 - accuracy: 0.8608 - val_loss: 6.9870 - val_accuracy: 0.1500\n",
      "Epoch 422/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.3955 - accuracy: 0.8608 - val_loss: 7.0056 - val_accuracy: 0.1500\n",
      "Epoch 423/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3948 - accuracy: 0.8608 - val_loss: 7.0239 - val_accuracy: 0.1500\n",
      "Epoch 424/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.3940 - accuracy: 0.8608 - val_loss: 7.0419 - val_accuracy: 0.1500\n",
      "Epoch 425/500\n",
      "79/79 [==============================] - 0s 37us/step - loss: 0.3933 - accuracy: 0.8608 - val_loss: 7.0599 - val_accuracy: 0.1500\n",
      "Epoch 426/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.3925 - accuracy: 0.8608 - val_loss: 7.0779 - val_accuracy: 0.1500\n",
      "Epoch 427/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.3918 - accuracy: 0.8608 - val_loss: 7.0960 - val_accuracy: 0.1500\n",
      "Epoch 428/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3911 - accuracy: 0.8608 - val_loss: 7.1137 - val_accuracy: 0.1500\n",
      "Epoch 429/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.3903 - accuracy: 0.8608 - val_loss: 7.1313 - val_accuracy: 0.1500\n",
      "Epoch 430/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3896 - accuracy: 0.8608 - val_loss: 7.1485 - val_accuracy: 0.1500\n",
      "Epoch 431/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3888 - accuracy: 0.8608 - val_loss: 7.1657 - val_accuracy: 0.1500\n",
      "Epoch 432/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3881 - accuracy: 0.8608 - val_loss: 7.1832 - val_accuracy: 0.1500\n",
      "Epoch 433/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3874 - accuracy: 0.8608 - val_loss: 7.2012 - val_accuracy: 0.1500\n",
      "Epoch 434/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.3867 - accuracy: 0.8608 - val_loss: 7.2187 - val_accuracy: 0.1500\n",
      "Epoch 435/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.3859 - accuracy: 0.8608 - val_loss: 7.2359 - val_accuracy: 0.1500\n",
      "Epoch 436/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.3852 - accuracy: 0.8608 - val_loss: 7.2535 - val_accuracy: 0.1500\n",
      "Epoch 437/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.3845 - accuracy: 0.8608 - val_loss: 7.2715 - val_accuracy: 0.1500\n",
      "Epoch 438/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3838 - accuracy: 0.8608 - val_loss: 7.2890 - val_accuracy: 0.1500\n",
      "Epoch 439/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3831 - accuracy: 0.8608 - val_loss: 7.3058 - val_accuracy: 0.1500\n",
      "Epoch 440/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.3824 - accuracy: 0.8608 - val_loss: 7.3219 - val_accuracy: 0.1500\n",
      "Epoch 441/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.3817 - accuracy: 0.8608 - val_loss: 7.3381 - val_accuracy: 0.1500\n",
      "Epoch 442/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3809 - accuracy: 0.8608 - val_loss: 7.3543 - val_accuracy: 0.1500\n",
      "Epoch 443/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3802 - accuracy: 0.8608 - val_loss: 7.3708 - val_accuracy: 0.1500\n",
      "Epoch 444/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3795 - accuracy: 0.8608 - val_loss: 7.3878 - val_accuracy: 0.1500\n",
      "Epoch 445/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3788 - accuracy: 0.8608 - val_loss: 7.4051 - val_accuracy: 0.1500\n",
      "Epoch 446/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.3781 - accuracy: 0.8608 - val_loss: 7.4217 - val_accuracy: 0.1500\n",
      "Epoch 447/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.3774 - accuracy: 0.8608 - val_loss: 7.4384 - val_accuracy: 0.1500\n",
      "Epoch 448/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3767 - accuracy: 0.8608 - val_loss: 7.4555 - val_accuracy: 0.1500\n",
      "Epoch 449/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3760 - accuracy: 0.8481 - val_loss: 7.4724 - val_accuracy: 0.1500\n",
      "Epoch 450/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3753 - accuracy: 0.8481 - val_loss: 7.4890 - val_accuracy: 0.1500\n",
      "Epoch 451/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.3746 - accuracy: 0.8481 - val_loss: 7.5054 - val_accuracy: 0.1500\n",
      "Epoch 452/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3739 - accuracy: 0.8481 - val_loss: 7.5218 - val_accuracy: 0.1500\n",
      "Epoch 453/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3732 - accuracy: 0.8481 - val_loss: 7.5380 - val_accuracy: 0.1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 454/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3725 - accuracy: 0.8481 - val_loss: 7.5546 - val_accuracy: 0.1500\n",
      "Epoch 455/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3718 - accuracy: 0.8481 - val_loss: 7.5710 - val_accuracy: 0.1500\n",
      "Epoch 456/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3711 - accuracy: 0.8481 - val_loss: 7.5874 - val_accuracy: 0.1500\n",
      "Epoch 457/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.3705 - accuracy: 0.8481 - val_loss: 7.6040 - val_accuracy: 0.1500\n",
      "Epoch 458/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3698 - accuracy: 0.8481 - val_loss: 7.6205 - val_accuracy: 0.1500\n",
      "Epoch 459/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.3691 - accuracy: 0.8481 - val_loss: 7.6366 - val_accuracy: 0.1500\n",
      "Epoch 460/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.3684 - accuracy: 0.8481 - val_loss: 7.6526 - val_accuracy: 0.1500\n",
      "Epoch 461/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.3677 - accuracy: 0.8481 - val_loss: 7.6689 - val_accuracy: 0.1500\n",
      "Epoch 462/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3671 - accuracy: 0.8481 - val_loss: 7.6859 - val_accuracy: 0.1500\n",
      "Epoch 463/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.3664 - accuracy: 0.8481 - val_loss: 7.7023 - val_accuracy: 0.1500\n",
      "Epoch 464/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3657 - accuracy: 0.8481 - val_loss: 7.7183 - val_accuracy: 0.1500\n",
      "Epoch 465/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3650 - accuracy: 0.8481 - val_loss: 7.7339 - val_accuracy: 0.1500\n",
      "Epoch 466/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3643 - accuracy: 0.8481 - val_loss: 7.7497 - val_accuracy: 0.1500\n",
      "Epoch 467/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.3636 - accuracy: 0.8481 - val_loss: 7.7659 - val_accuracy: 0.1500\n",
      "Epoch 468/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.3630 - accuracy: 0.8481 - val_loss: 7.7822 - val_accuracy: 0.1500\n",
      "Epoch 469/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3623 - accuracy: 0.8481 - val_loss: 7.7984 - val_accuracy: 0.1500\n",
      "Epoch 470/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3616 - accuracy: 0.8481 - val_loss: 7.8146 - val_accuracy: 0.1500\n",
      "Epoch 471/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3609 - accuracy: 0.8481 - val_loss: 7.8313 - val_accuracy: 0.1500\n",
      "Epoch 472/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3602 - accuracy: 0.8481 - val_loss: 7.8487 - val_accuracy: 0.1500\n",
      "Epoch 473/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.3596 - accuracy: 0.8481 - val_loss: 7.8655 - val_accuracy: 0.1500\n",
      "Epoch 474/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.3589 - accuracy: 0.8481 - val_loss: 7.8818 - val_accuracy: 0.1500\n",
      "Epoch 475/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.3583 - accuracy: 0.8481 - val_loss: 7.8981 - val_accuracy: 0.1500\n",
      "Epoch 476/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3576 - accuracy: 0.8481 - val_loss: 7.9142 - val_accuracy: 0.1500\n",
      "Epoch 477/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3569 - accuracy: 0.8481 - val_loss: 7.9302 - val_accuracy: 0.1500\n",
      "Epoch 478/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3563 - accuracy: 0.8481 - val_loss: 7.9462 - val_accuracy: 0.1500\n",
      "Epoch 479/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.3556 - accuracy: 0.8481 - val_loss: 7.9623 - val_accuracy: 0.1500\n",
      "Epoch 480/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.3550 - accuracy: 0.8481 - val_loss: 7.9784 - val_accuracy: 0.1500\n",
      "Epoch 481/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.3543 - accuracy: 0.8481 - val_loss: 7.9919 - val_accuracy: 0.1500\n",
      "Epoch 482/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3537 - accuracy: 0.8481 - val_loss: 8.0051 - val_accuracy: 0.1500\n",
      "Epoch 483/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.3530 - accuracy: 0.8481 - val_loss: 8.0180 - val_accuracy: 0.1500\n",
      "Epoch 484/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3523 - accuracy: 0.8481 - val_loss: 8.0307 - val_accuracy: 0.1500\n",
      "Epoch 485/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3517 - accuracy: 0.8481 - val_loss: 8.0430 - val_accuracy: 0.1500\n",
      "Epoch 486/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.3511 - accuracy: 0.8608 - val_loss: 8.0555 - val_accuracy: 0.1500\n",
      "Epoch 487/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3504 - accuracy: 0.8608 - val_loss: 8.0682 - val_accuracy: 0.1500\n",
      "Epoch 488/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3498 - accuracy: 0.8608 - val_loss: 8.0811 - val_accuracy: 0.1500\n",
      "Epoch 489/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3492 - accuracy: 0.8608 - val_loss: 8.0940 - val_accuracy: 0.1500\n",
      "Epoch 490/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3485 - accuracy: 0.8608 - val_loss: 8.1069 - val_accuracy: 0.1500\n",
      "Epoch 491/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3479 - accuracy: 0.8608 - val_loss: 8.1192 - val_accuracy: 0.1500\n",
      "Epoch 492/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3472 - accuracy: 0.8608 - val_loss: 8.1314 - val_accuracy: 0.1500\n",
      "Epoch 493/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3466 - accuracy: 0.8608 - val_loss: 8.1442 - val_accuracy: 0.1500\n",
      "Epoch 494/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.3460 - accuracy: 0.8608 - val_loss: 8.1569 - val_accuracy: 0.1500\n",
      "Epoch 495/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3453 - accuracy: 0.8608 - val_loss: 8.1689 - val_accuracy: 0.1500\n",
      "Epoch 496/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3447 - accuracy: 0.8608 - val_loss: 8.1805 - val_accuracy: 0.1500\n",
      "Epoch 497/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.3441 - accuracy: 0.8608 - val_loss: 8.1925 - val_accuracy: 0.1500\n",
      "Epoch 498/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3434 - accuracy: 0.8608 - val_loss: 8.2049 - val_accuracy: 0.1500\n",
      "Epoch 499/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.3428 - accuracy: 0.8608 - val_loss: 8.2173 - val_accuracy: 0.1500\n",
      "Epoch 500/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.3422 - accuracy: 0.8608 - val_loss: 8.2297 - val_accuracy: 0.1500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x25ea96041d0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#加上一回合，沒有放 delta_Price\n",
    "with open('001_b_1110_1_1_p1.csv', newline='') as csvfile1:\n",
    "    data1 = pd.read_csv(csvfile1)\n",
    "    data1 = data1[0:100]\n",
    "with open('002_b_1110_1_1_p2.csv', newline='') as csvfile2:\n",
    "    data2 = pd.read_csv(csvfile2)\n",
    "    data2 = data2[0:100]\n",
    "    \n",
    "X = data1.loc[:,['p1Cash','StockPrice','p1TotalAsset']]\n",
    "X['p2TotalAsset'] = data2.loc[:,['p2TotalAsset']]\n",
    "X['p1ChechHistory'] = pd.get_dummies(data1.loc[:,'p1ChechHistory'])['yes']\n",
    "X_1_100 = X[1:100]\n",
    "X_1_100 = X_1_100.reset_index()\n",
    "X_0_99 = X[0:99]\n",
    "X_0_99 = X_0_99.rename(columns = {'p1Cash':'pre_p1Cash','StockPrice':'pre_StockPrice','p1TotalAsset':'pre_p1TotalAsset',\n",
    "                                 'p2TotalAsset':'pre_p2TotalAsset','p1ChechHistory':'pre_p1ChechHistory'}, inplace = False)\n",
    "X = pd.concat([X_1_100,X_0_99], axis=1)\n",
    "X = X.drop(['index'], axis = 1)\n",
    "\n",
    "X = preprocessing.scale(X)\n",
    "\n",
    "Y = data1.loc[:,'p1Decision']\n",
    "Y_dum = pd.get_dummies(Y)\n",
    "Y = Y_dum[1:100]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(80, input_dim = 10, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "model.fit(X,Y, epochs = 500, batch_size = 80, validation_split = 0.2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 80)                880       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 243       \n",
      "=================================================================\n",
      "Total params: 1,123\n",
      "Trainable params: 1,123\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_3_input to have shape (10,) but got array with shape (5,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-fe1bd9112ccd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\anaconda\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    143\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    146\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_3_input to have shape (10,) but got array with shape (5,)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model = Sequential()\n",
    "model.add(Dense(80, input_dim = 10, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "test = model.fit(X,Y, epochs = 500, batch_size = 80, validation_split = 0.2, shuffle = True)\n",
    "plt.plot(test.history['accuracy'])\n",
    "plt.plot(test.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(test.history['loss'])\n",
    "plt.plot(test.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 80)                960       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 243       \n",
      "=================================================================\n",
      "Total params: 1,203\n",
      "Trainable params: 1,203\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 79 samples, validate on 20 samples\n",
      "Epoch 1/500\n",
      "79/79 [==============================] - 0s 903us/step - loss: 1.1278 - accuracy: 0.2911 - val_loss: 1.0765 - val_accuracy: 0.4500\n",
      "Epoch 2/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 1.1214 - accuracy: 0.3165 - val_loss: 1.0811 - val_accuracy: 0.4000\n",
      "Epoch 3/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 1.1142 - accuracy: 0.3165 - val_loss: 1.0866 - val_accuracy: 0.3500\n",
      "Epoch 4/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 1.1059 - accuracy: 0.3165 - val_loss: 1.0921 - val_accuracy: 0.3500\n",
      "Epoch 5/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 1.0978 - accuracy: 0.3165 - val_loss: 1.0974 - val_accuracy: 0.3500\n",
      "Epoch 6/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 1.0902 - accuracy: 0.3418 - val_loss: 1.1028 - val_accuracy: 0.3500\n",
      "Epoch 7/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 1.0827 - accuracy: 0.3544 - val_loss: 1.1085 - val_accuracy: 0.3000\n",
      "Epoch 8/500\n",
      "79/79 [==============================] - 0s 51us/step - loss: 1.0752 - accuracy: 0.4177 - val_loss: 1.1143 - val_accuracy: 0.3000\n",
      "Epoch 9/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 1.0679 - accuracy: 0.5063 - val_loss: 1.1201 - val_accuracy: 0.2000\n",
      "Epoch 10/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 1.0607 - accuracy: 0.4937 - val_loss: 1.1259 - val_accuracy: 0.2000\n",
      "Epoch 11/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 1.0537 - accuracy: 0.5063 - val_loss: 1.1320 - val_accuracy: 0.2500\n",
      "Epoch 12/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 1.0468 - accuracy: 0.5063 - val_loss: 1.1380 - val_accuracy: 0.2500\n",
      "Epoch 13/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 1.0400 - accuracy: 0.5190 - val_loss: 1.1441 - val_accuracy: 0.2500\n",
      "Epoch 14/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 1.0334 - accuracy: 0.5443 - val_loss: 1.1505 - val_accuracy: 0.2500\n",
      "Epoch 15/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 1.0268 - accuracy: 0.5443 - val_loss: 1.1568 - val_accuracy: 0.2500\n",
      "Epoch 16/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 1.0204 - accuracy: 0.5443 - val_loss: 1.1632 - val_accuracy: 0.1500\n",
      "Epoch 17/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 1.0140 - accuracy: 0.5316 - val_loss: 1.1697 - val_accuracy: 0.1500\n",
      "Epoch 18/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 1.0078 - accuracy: 0.5316 - val_loss: 1.1764 - val_accuracy: 0.1500\n",
      "Epoch 19/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 1.0017 - accuracy: 0.5316 - val_loss: 1.1831 - val_accuracy: 0.1500\n",
      "Epoch 20/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9957 - accuracy: 0.5190 - val_loss: 1.1900 - val_accuracy: 0.1000\n",
      "Epoch 21/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9898 - accuracy: 0.5190 - val_loss: 1.1971 - val_accuracy: 0.1000\n",
      "Epoch 22/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.9840 - accuracy: 0.5190 - val_loss: 1.2043 - val_accuracy: 0.1000\n",
      "Epoch 23/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9783 - accuracy: 0.5316 - val_loss: 1.2116 - val_accuracy: 0.1000\n",
      "Epoch 24/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9727 - accuracy: 0.5316 - val_loss: 1.2191 - val_accuracy: 0.1000\n",
      "Epoch 25/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9673 - accuracy: 0.5316 - val_loss: 1.2267 - val_accuracy: 0.1000\n",
      "Epoch 26/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.9620 - accuracy: 0.5316 - val_loss: 1.2345 - val_accuracy: 0.1000\n",
      "Epoch 27/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9568 - accuracy: 0.5316 - val_loss: 1.2426 - val_accuracy: 0.1000\n",
      "Epoch 28/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.9518 - accuracy: 0.5443 - val_loss: 1.2508 - val_accuracy: 0.1000\n",
      "Epoch 29/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9469 - accuracy: 0.5443 - val_loss: 1.2592 - val_accuracy: 0.1000\n",
      "Epoch 30/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9421 - accuracy: 0.5443 - val_loss: 1.2679 - val_accuracy: 0.1000\n",
      "Epoch 31/500\n",
      "79/79 [==============================] - 0s 37us/step - loss: 0.9374 - accuracy: 0.5443 - val_loss: 1.2768 - val_accuracy: 0.1000\n",
      "Epoch 32/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9328 - accuracy: 0.5443 - val_loss: 1.2859 - val_accuracy: 0.1000\n",
      "Epoch 33/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.9283 - accuracy: 0.5443 - val_loss: 1.2951 - val_accuracy: 0.1000\n",
      "Epoch 34/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.9239 - accuracy: 0.5570 - val_loss: 1.3046 - val_accuracy: 0.1000\n",
      "Epoch 35/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9195 - accuracy: 0.5570 - val_loss: 1.3141 - val_accuracy: 0.1000\n",
      "Epoch 36/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.9153 - accuracy: 0.5696 - val_loss: 1.3239 - val_accuracy: 0.1000\n",
      "Epoch 37/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9110 - accuracy: 0.5696 - val_loss: 1.3338 - val_accuracy: 0.1000\n",
      "Epoch 38/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.9069 - accuracy: 0.5696 - val_loss: 1.3439 - val_accuracy: 0.1000\n",
      "Epoch 39/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.9028 - accuracy: 0.5696 - val_loss: 1.3540 - val_accuracy: 0.1000\n",
      "Epoch 40/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8989 - accuracy: 0.5696 - val_loss: 1.3645 - val_accuracy: 0.1000\n",
      "Epoch 41/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.8949 - accuracy: 0.5696 - val_loss: 1.3749 - val_accuracy: 0.1000\n",
      "Epoch 42/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8911 - accuracy: 0.5696 - val_loss: 1.3857 - val_accuracy: 0.1000\n",
      "Epoch 43/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8873 - accuracy: 0.5696 - val_loss: 1.3964 - val_accuracy: 0.1000\n",
      "Epoch 44/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8835 - accuracy: 0.5696 - val_loss: 1.4075 - val_accuracy: 0.1000\n",
      "Epoch 45/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8798 - accuracy: 0.5696 - val_loss: 1.4187 - val_accuracy: 0.1000\n",
      "Epoch 46/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.8761 - accuracy: 0.5823 - val_loss: 1.4300 - val_accuracy: 0.1000\n",
      "Epoch 47/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8724 - accuracy: 0.5823 - val_loss: 1.4414 - val_accuracy: 0.1000\n",
      "Epoch 48/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.8688 - accuracy: 0.5823 - val_loss: 1.4530 - val_accuracy: 0.1000\n",
      "Epoch 49/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8653 - accuracy: 0.5823 - val_loss: 1.4646 - val_accuracy: 0.1000\n",
      "Epoch 50/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8618 - accuracy: 0.5823 - val_loss: 1.4764 - val_accuracy: 0.1000\n",
      "Epoch 51/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8584 - accuracy: 0.5823 - val_loss: 1.4883 - val_accuracy: 0.1000\n",
      "Epoch 52/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.8550 - accuracy: 0.5949 - val_loss: 1.5003 - val_accuracy: 0.1000\n",
      "Epoch 53/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.8516 - accuracy: 0.6076 - val_loss: 1.5126 - val_accuracy: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8482 - accuracy: 0.6076 - val_loss: 1.5251 - val_accuracy: 0.1000\n",
      "Epoch 55/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8449 - accuracy: 0.6076 - val_loss: 1.5378 - val_accuracy: 0.1000\n",
      "Epoch 56/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8417 - accuracy: 0.6076 - val_loss: 1.5508 - val_accuracy: 0.1000\n",
      "Epoch 57/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8384 - accuracy: 0.6076 - val_loss: 1.5638 - val_accuracy: 0.1000\n",
      "Epoch 58/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8353 - accuracy: 0.6203 - val_loss: 1.5772 - val_accuracy: 0.1000\n",
      "Epoch 59/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8321 - accuracy: 0.6203 - val_loss: 1.5906 - val_accuracy: 0.1000\n",
      "Epoch 60/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8290 - accuracy: 0.6203 - val_loss: 1.6042 - val_accuracy: 0.1000\n",
      "Epoch 61/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8260 - accuracy: 0.6076 - val_loss: 1.6181 - val_accuracy: 0.1000\n",
      "Epoch 62/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8229 - accuracy: 0.6076 - val_loss: 1.6321 - val_accuracy: 0.1000\n",
      "Epoch 63/500\n",
      "79/79 [==============================] - 0s 37us/step - loss: 0.8199 - accuracy: 0.6203 - val_loss: 1.6463 - val_accuracy: 0.1000\n",
      "Epoch 64/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8169 - accuracy: 0.6203 - val_loss: 1.6605 - val_accuracy: 0.1000\n",
      "Epoch 65/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.8139 - accuracy: 0.6203 - val_loss: 1.6749 - val_accuracy: 0.1000\n",
      "Epoch 66/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8110 - accuracy: 0.6203 - val_loss: 1.6895 - val_accuracy: 0.1000\n",
      "Epoch 67/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8082 - accuracy: 0.6203 - val_loss: 1.7042 - val_accuracy: 0.1000\n",
      "Epoch 68/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.8054 - accuracy: 0.6203 - val_loss: 1.7188 - val_accuracy: 0.1000\n",
      "Epoch 69/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.8026 - accuracy: 0.6076 - val_loss: 1.7338 - val_accuracy: 0.1000\n",
      "Epoch 70/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7998 - accuracy: 0.6076 - val_loss: 1.7487 - val_accuracy: 0.1000\n",
      "Epoch 71/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7971 - accuracy: 0.6076 - val_loss: 1.7638 - val_accuracy: 0.1000\n",
      "Epoch 72/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7943 - accuracy: 0.6076 - val_loss: 1.7794 - val_accuracy: 0.1000\n",
      "Epoch 73/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.7916 - accuracy: 0.6076 - val_loss: 1.7950 - val_accuracy: 0.1000\n",
      "Epoch 74/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7889 - accuracy: 0.6076 - val_loss: 1.8109 - val_accuracy: 0.1000\n",
      "Epoch 75/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7862 - accuracy: 0.6076 - val_loss: 1.8270 - val_accuracy: 0.1000\n",
      "Epoch 76/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7836 - accuracy: 0.6076 - val_loss: 1.8435 - val_accuracy: 0.1000\n",
      "Epoch 77/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7809 - accuracy: 0.6076 - val_loss: 1.8600 - val_accuracy: 0.1000\n",
      "Epoch 78/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7783 - accuracy: 0.5949 - val_loss: 1.8767 - val_accuracy: 0.1000\n",
      "Epoch 79/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7758 - accuracy: 0.5949 - val_loss: 1.8933 - val_accuracy: 0.1000\n",
      "Epoch 80/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.7732 - accuracy: 0.5949 - val_loss: 1.9101 - val_accuracy: 0.1000\n",
      "Epoch 81/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7707 - accuracy: 0.5949 - val_loss: 1.9272 - val_accuracy: 0.1000\n",
      "Epoch 82/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7682 - accuracy: 0.5949 - val_loss: 1.9443 - val_accuracy: 0.1000\n",
      "Epoch 83/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7658 - accuracy: 0.5949 - val_loss: 1.9615 - val_accuracy: 0.1000\n",
      "Epoch 84/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.7633 - accuracy: 0.5949 - val_loss: 1.9787 - val_accuracy: 0.1000\n",
      "Epoch 85/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7609 - accuracy: 0.5949 - val_loss: 1.9958 - val_accuracy: 0.1000\n",
      "Epoch 86/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7585 - accuracy: 0.5949 - val_loss: 2.0131 - val_accuracy: 0.1000\n",
      "Epoch 87/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.7561 - accuracy: 0.5949 - val_loss: 2.0305 - val_accuracy: 0.1000\n",
      "Epoch 88/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.7538 - accuracy: 0.5949 - val_loss: 2.0480 - val_accuracy: 0.1000\n",
      "Epoch 89/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7514 - accuracy: 0.5949 - val_loss: 2.0656 - val_accuracy: 0.1000\n",
      "Epoch 90/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7491 - accuracy: 0.5823 - val_loss: 2.0831 - val_accuracy: 0.1000\n",
      "Epoch 91/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7469 - accuracy: 0.5823 - val_loss: 2.1001 - val_accuracy: 0.1000\n",
      "Epoch 92/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7446 - accuracy: 0.5823 - val_loss: 2.1170 - val_accuracy: 0.1000\n",
      "Epoch 93/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7424 - accuracy: 0.5823 - val_loss: 2.1338 - val_accuracy: 0.1000\n",
      "Epoch 94/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7402 - accuracy: 0.5823 - val_loss: 2.1504 - val_accuracy: 0.1000\n",
      "Epoch 95/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7380 - accuracy: 0.5823 - val_loss: 2.1671 - val_accuracy: 0.1000\n",
      "Epoch 96/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.7358 - accuracy: 0.5823 - val_loss: 2.1837 - val_accuracy: 0.1000\n",
      "Epoch 97/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.7337 - accuracy: 0.5823 - val_loss: 2.2004 - val_accuracy: 0.1000\n",
      "Epoch 98/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7316 - accuracy: 0.5823 - val_loss: 2.2169 - val_accuracy: 0.1000\n",
      "Epoch 99/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7294 - accuracy: 0.5823 - val_loss: 2.2334 - val_accuracy: 0.1000\n",
      "Epoch 100/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7274 - accuracy: 0.5823 - val_loss: 2.2499 - val_accuracy: 0.1000\n",
      "Epoch 101/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7253 - accuracy: 0.5823 - val_loss: 2.2665 - val_accuracy: 0.1000\n",
      "Epoch 102/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7232 - accuracy: 0.5823 - val_loss: 2.2831 - val_accuracy: 0.1000\n",
      "Epoch 103/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7212 - accuracy: 0.5823 - val_loss: 2.2997 - val_accuracy: 0.1000\n",
      "Epoch 104/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.7191 - accuracy: 0.5823 - val_loss: 2.3162 - val_accuracy: 0.1000\n",
      "Epoch 105/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7171 - accuracy: 0.5823 - val_loss: 2.3325 - val_accuracy: 0.1000\n",
      "Epoch 106/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7151 - accuracy: 0.5823 - val_loss: 2.3488 - val_accuracy: 0.1000\n",
      "Epoch 107/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7131 - accuracy: 0.5696 - val_loss: 2.3649 - val_accuracy: 0.1000\n",
      "Epoch 108/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.7111 - accuracy: 0.5696 - val_loss: 2.3808 - val_accuracy: 0.1000\n",
      "Epoch 109/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7092 - accuracy: 0.5696 - val_loss: 2.3967 - val_accuracy: 0.1000\n",
      "Epoch 110/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.7073 - accuracy: 0.5696 - val_loss: 2.4125 - val_accuracy: 0.1000\n",
      "Epoch 111/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.7053 - accuracy: 0.5696 - val_loss: 2.4281 - val_accuracy: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.7034 - accuracy: 0.5696 - val_loss: 2.4435 - val_accuracy: 0.1000\n",
      "Epoch 113/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.7015 - accuracy: 0.5696 - val_loss: 2.4586 - val_accuracy: 0.1000\n",
      "Epoch 114/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6997 - accuracy: 0.5823 - val_loss: 2.4734 - val_accuracy: 0.1000\n",
      "Epoch 115/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6978 - accuracy: 0.5949 - val_loss: 2.4880 - val_accuracy: 0.1000\n",
      "Epoch 116/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.6959 - accuracy: 0.6076 - val_loss: 2.5025 - val_accuracy: 0.1000\n",
      "Epoch 117/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6941 - accuracy: 0.6329 - val_loss: 2.5170 - val_accuracy: 0.1000\n",
      "Epoch 118/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6922 - accuracy: 0.6329 - val_loss: 2.5314 - val_accuracy: 0.1000\n",
      "Epoch 119/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6903 - accuracy: 0.6329 - val_loss: 2.5457 - val_accuracy: 0.1000\n",
      "Epoch 120/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6885 - accuracy: 0.6329 - val_loss: 2.5600 - val_accuracy: 0.1000\n",
      "Epoch 121/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.6866 - accuracy: 0.6329 - val_loss: 2.5741 - val_accuracy: 0.1000\n",
      "Epoch 122/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6848 - accuracy: 0.6329 - val_loss: 2.5880 - val_accuracy: 0.1500\n",
      "Epoch 123/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6830 - accuracy: 0.6329 - val_loss: 2.6020 - val_accuracy: 0.1500\n",
      "Epoch 124/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6811 - accuracy: 0.6329 - val_loss: 2.6157 - val_accuracy: 0.1500\n",
      "Epoch 125/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.6793 - accuracy: 0.6329 - val_loss: 2.6294 - val_accuracy: 0.1500\n",
      "Epoch 126/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.6775 - accuracy: 0.6329 - val_loss: 2.6429 - val_accuracy: 0.1500\n",
      "Epoch 127/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.6757 - accuracy: 0.6329 - val_loss: 2.6564 - val_accuracy: 0.1500\n",
      "Epoch 128/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6739 - accuracy: 0.6329 - val_loss: 2.6700 - val_accuracy: 0.1500\n",
      "Epoch 129/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6721 - accuracy: 0.6456 - val_loss: 2.6834 - val_accuracy: 0.1500\n",
      "Epoch 130/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.6703 - accuracy: 0.6456 - val_loss: 2.6969 - val_accuracy: 0.1500\n",
      "Epoch 131/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6686 - accuracy: 0.6456 - val_loss: 2.7102 - val_accuracy: 0.1500\n",
      "Epoch 132/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.6668 - accuracy: 0.6456 - val_loss: 2.7234 - val_accuracy: 0.1500\n",
      "Epoch 133/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.6650 - accuracy: 0.6456 - val_loss: 2.7366 - val_accuracy: 0.1500\n",
      "Epoch 134/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6633 - accuracy: 0.6456 - val_loss: 2.7497 - val_accuracy: 0.1500\n",
      "Epoch 135/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6615 - accuracy: 0.6456 - val_loss: 2.7630 - val_accuracy: 0.1500\n",
      "Epoch 136/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.6598 - accuracy: 0.6456 - val_loss: 2.7763 - val_accuracy: 0.1500\n",
      "Epoch 137/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6580 - accuracy: 0.6456 - val_loss: 2.7898 - val_accuracy: 0.1500\n",
      "Epoch 138/500\n",
      "79/79 [==============================] - 0s 37us/step - loss: 0.6563 - accuracy: 0.6582 - val_loss: 2.8033 - val_accuracy: 0.1500\n",
      "Epoch 139/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6546 - accuracy: 0.6582 - val_loss: 2.8168 - val_accuracy: 0.1500\n",
      "Epoch 140/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6528 - accuracy: 0.6582 - val_loss: 2.8302 - val_accuracy: 0.1500\n",
      "Epoch 141/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6511 - accuracy: 0.6582 - val_loss: 2.8434 - val_accuracy: 0.1500\n",
      "Epoch 142/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6494 - accuracy: 0.6582 - val_loss: 2.8566 - val_accuracy: 0.1500\n",
      "Epoch 143/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6477 - accuracy: 0.6582 - val_loss: 2.8700 - val_accuracy: 0.1500\n",
      "Epoch 144/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6461 - accuracy: 0.6582 - val_loss: 2.8836 - val_accuracy: 0.1500\n",
      "Epoch 145/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.6444 - accuracy: 0.6582 - val_loss: 2.8977 - val_accuracy: 0.1500\n",
      "Epoch 146/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6428 - accuracy: 0.6582 - val_loss: 2.9121 - val_accuracy: 0.1500\n",
      "Epoch 147/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6411 - accuracy: 0.6582 - val_loss: 2.9267 - val_accuracy: 0.1500\n",
      "Epoch 148/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6394 - accuracy: 0.6582 - val_loss: 2.9415 - val_accuracy: 0.1500\n",
      "Epoch 149/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.6377 - accuracy: 0.6582 - val_loss: 2.9566 - val_accuracy: 0.1500\n",
      "Epoch 150/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6360 - accuracy: 0.6582 - val_loss: 2.9718 - val_accuracy: 0.1500\n",
      "Epoch 151/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6344 - accuracy: 0.6709 - val_loss: 2.9870 - val_accuracy: 0.1500\n",
      "Epoch 152/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6327 - accuracy: 0.6709 - val_loss: 3.0020 - val_accuracy: 0.1500\n",
      "Epoch 153/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.6310 - accuracy: 0.6709 - val_loss: 3.0170 - val_accuracy: 0.1500\n",
      "Epoch 154/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6294 - accuracy: 0.6709 - val_loss: 3.0320 - val_accuracy: 0.1500\n",
      "Epoch 155/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.6277 - accuracy: 0.6709 - val_loss: 3.0470 - val_accuracy: 0.1500\n",
      "Epoch 156/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.6261 - accuracy: 0.6709 - val_loss: 3.0623 - val_accuracy: 0.1500\n",
      "Epoch 157/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.6244 - accuracy: 0.6709 - val_loss: 3.0777 - val_accuracy: 0.1500\n",
      "Epoch 158/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6228 - accuracy: 0.6709 - val_loss: 3.0933 - val_accuracy: 0.1500\n",
      "Epoch 159/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.6211 - accuracy: 0.6709 - val_loss: 3.1089 - val_accuracy: 0.1500\n",
      "Epoch 160/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6195 - accuracy: 0.6709 - val_loss: 3.1243 - val_accuracy: 0.1500\n",
      "Epoch 161/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.6179 - accuracy: 0.6709 - val_loss: 3.1393 - val_accuracy: 0.1500\n",
      "Epoch 162/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6162 - accuracy: 0.6709 - val_loss: 3.1542 - val_accuracy: 0.1500\n",
      "Epoch 163/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.6146 - accuracy: 0.6962 - val_loss: 3.1692 - val_accuracy: 0.1500\n",
      "Epoch 164/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6130 - accuracy: 0.6962 - val_loss: 3.1843 - val_accuracy: 0.1500\n",
      "Epoch 165/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6114 - accuracy: 0.6962 - val_loss: 3.1997 - val_accuracy: 0.1500\n",
      "Epoch 166/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6098 - accuracy: 0.6962 - val_loss: 3.2153 - val_accuracy: 0.1500\n",
      "Epoch 167/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6081 - accuracy: 0.6962 - val_loss: 3.2311 - val_accuracy: 0.1500\n",
      "Epoch 168/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.6065 - accuracy: 0.6962 - val_loss: 3.2467 - val_accuracy: 0.1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6049 - accuracy: 0.6962 - val_loss: 3.2622 - val_accuracy: 0.1500\n",
      "Epoch 170/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6033 - accuracy: 0.6962 - val_loss: 3.2778 - val_accuracy: 0.1500\n",
      "Epoch 171/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6017 - accuracy: 0.7089 - val_loss: 3.2936 - val_accuracy: 0.1500\n",
      "Epoch 172/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.6000 - accuracy: 0.7089 - val_loss: 3.3091 - val_accuracy: 0.1500\n",
      "Epoch 173/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5984 - accuracy: 0.7089 - val_loss: 3.3246 - val_accuracy: 0.1500\n",
      "Epoch 174/500\n",
      "79/79 [==============================] - 0s 37us/step - loss: 0.5968 - accuracy: 0.7089 - val_loss: 3.3402 - val_accuracy: 0.1500\n",
      "Epoch 175/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.5952 - accuracy: 0.7089 - val_loss: 3.3560 - val_accuracy: 0.1500\n",
      "Epoch 176/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.5936 - accuracy: 0.6962 - val_loss: 3.3719 - val_accuracy: 0.1500\n",
      "Epoch 177/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5920 - accuracy: 0.6962 - val_loss: 3.3882 - val_accuracy: 0.1500\n",
      "Epoch 178/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5904 - accuracy: 0.6962 - val_loss: 3.4050 - val_accuracy: 0.1500\n",
      "Epoch 179/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5888 - accuracy: 0.6962 - val_loss: 3.4221 - val_accuracy: 0.1500\n",
      "Epoch 180/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5872 - accuracy: 0.6962 - val_loss: 3.4391 - val_accuracy: 0.1500\n",
      "Epoch 181/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.5856 - accuracy: 0.6962 - val_loss: 3.4557 - val_accuracy: 0.1500\n",
      "Epoch 182/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5840 - accuracy: 0.6962 - val_loss: 3.4723 - val_accuracy: 0.1500\n",
      "Epoch 183/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.5824 - accuracy: 0.6962 - val_loss: 3.4889 - val_accuracy: 0.1500\n",
      "Epoch 184/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5808 - accuracy: 0.6962 - val_loss: 3.5057 - val_accuracy: 0.1500\n",
      "Epoch 185/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5792 - accuracy: 0.7089 - val_loss: 3.5230 - val_accuracy: 0.1500\n",
      "Epoch 186/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5776 - accuracy: 0.6962 - val_loss: 3.5404 - val_accuracy: 0.1500\n",
      "Epoch 187/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.5761 - accuracy: 0.6962 - val_loss: 3.5584 - val_accuracy: 0.1500\n",
      "Epoch 188/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.5745 - accuracy: 0.7089 - val_loss: 3.5765 - val_accuracy: 0.1500\n",
      "Epoch 189/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5729 - accuracy: 0.7089 - val_loss: 3.5949 - val_accuracy: 0.1500\n",
      "Epoch 190/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5714 - accuracy: 0.7089 - val_loss: 3.6134 - val_accuracy: 0.1500\n",
      "Epoch 191/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.5698 - accuracy: 0.7215 - val_loss: 3.6319 - val_accuracy: 0.1500\n",
      "Epoch 192/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.5682 - accuracy: 0.7215 - val_loss: 3.6503 - val_accuracy: 0.1500\n",
      "Epoch 193/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5666 - accuracy: 0.7215 - val_loss: 3.6687 - val_accuracy: 0.1500\n",
      "Epoch 194/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.5650 - accuracy: 0.7215 - val_loss: 3.6871 - val_accuracy: 0.1500\n",
      "Epoch 195/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5635 - accuracy: 0.7342 - val_loss: 3.7056 - val_accuracy: 0.1500\n",
      "Epoch 196/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5619 - accuracy: 0.7342 - val_loss: 3.7244 - val_accuracy: 0.1500\n",
      "Epoch 197/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5603 - accuracy: 0.7468 - val_loss: 3.7433 - val_accuracy: 0.1500\n",
      "Epoch 198/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5587 - accuracy: 0.7722 - val_loss: 3.7620 - val_accuracy: 0.1500\n",
      "Epoch 199/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5571 - accuracy: 0.7722 - val_loss: 3.7807 - val_accuracy: 0.1500\n",
      "Epoch 200/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5555 - accuracy: 0.7722 - val_loss: 3.7995 - val_accuracy: 0.1500\n",
      "Epoch 201/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5539 - accuracy: 0.7722 - val_loss: 3.8187 - val_accuracy: 0.1500\n",
      "Epoch 202/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.5524 - accuracy: 0.7722 - val_loss: 3.8383 - val_accuracy: 0.1500\n",
      "Epoch 203/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5507 - accuracy: 0.7722 - val_loss: 3.8580 - val_accuracy: 0.1500\n",
      "Epoch 204/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5491 - accuracy: 0.7722 - val_loss: 3.8776 - val_accuracy: 0.1500\n",
      "Epoch 205/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5475 - accuracy: 0.7722 - val_loss: 3.8971 - val_accuracy: 0.1500\n",
      "Epoch 206/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5459 - accuracy: 0.7722 - val_loss: 3.9164 - val_accuracy: 0.1500\n",
      "Epoch 207/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5443 - accuracy: 0.7722 - val_loss: 3.9359 - val_accuracy: 0.1500\n",
      "Epoch 208/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.5427 - accuracy: 0.7722 - val_loss: 3.9556 - val_accuracy: 0.1500\n",
      "Epoch 209/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5411 - accuracy: 0.7722 - val_loss: 3.9757 - val_accuracy: 0.1500\n",
      "Epoch 210/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.5395 - accuracy: 0.7722 - val_loss: 3.9958 - val_accuracy: 0.1500\n",
      "Epoch 211/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5379 - accuracy: 0.7722 - val_loss: 4.0162 - val_accuracy: 0.1500\n",
      "Epoch 212/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5363 - accuracy: 0.7848 - val_loss: 4.0370 - val_accuracy: 0.1500\n",
      "Epoch 213/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5347 - accuracy: 0.7848 - val_loss: 4.0581 - val_accuracy: 0.1500\n",
      "Epoch 214/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5331 - accuracy: 0.7848 - val_loss: 4.0791 - val_accuracy: 0.1500\n",
      "Epoch 215/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5315 - accuracy: 0.7848 - val_loss: 4.1001 - val_accuracy: 0.1500\n",
      "Epoch 216/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5300 - accuracy: 0.7848 - val_loss: 4.1212 - val_accuracy: 0.1500\n",
      "Epoch 217/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5284 - accuracy: 0.7848 - val_loss: 4.1426 - val_accuracy: 0.1500\n",
      "Epoch 218/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5268 - accuracy: 0.7975 - val_loss: 4.1641 - val_accuracy: 0.1500\n",
      "Epoch 219/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5252 - accuracy: 0.7975 - val_loss: 4.1858 - val_accuracy: 0.1500\n",
      "Epoch 220/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.5236 - accuracy: 0.7975 - val_loss: 4.2073 - val_accuracy: 0.1500\n",
      "Epoch 221/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5220 - accuracy: 0.7975 - val_loss: 4.2291 - val_accuracy: 0.1500\n",
      "Epoch 222/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5204 - accuracy: 0.7975 - val_loss: 4.2512 - val_accuracy: 0.1500\n",
      "Epoch 223/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5188 - accuracy: 0.8101 - val_loss: 4.2737 - val_accuracy: 0.1500\n",
      "Epoch 224/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.5172 - accuracy: 0.8101 - val_loss: 4.2964 - val_accuracy: 0.1500\n",
      "Epoch 225/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5156 - accuracy: 0.8101 - val_loss: 4.3193 - val_accuracy: 0.1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5140 - accuracy: 0.8101 - val_loss: 4.3423 - val_accuracy: 0.1500\n",
      "Epoch 227/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5125 - accuracy: 0.8228 - val_loss: 4.3654 - val_accuracy: 0.1500\n",
      "Epoch 228/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5109 - accuracy: 0.8228 - val_loss: 4.3883 - val_accuracy: 0.1500\n",
      "Epoch 229/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5093 - accuracy: 0.8228 - val_loss: 4.4110 - val_accuracy: 0.1500\n",
      "Epoch 230/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5078 - accuracy: 0.8228 - val_loss: 4.4338 - val_accuracy: 0.1500\n",
      "Epoch 231/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.5062 - accuracy: 0.8228 - val_loss: 4.4571 - val_accuracy: 0.1500\n",
      "Epoch 232/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5047 - accuracy: 0.8228 - val_loss: 4.4807 - val_accuracy: 0.1500\n",
      "Epoch 233/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5031 - accuracy: 0.8228 - val_loss: 4.5045 - val_accuracy: 0.1500\n",
      "Epoch 234/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5017 - accuracy: 0.8228 - val_loss: 4.5284 - val_accuracy: 0.1500\n",
      "Epoch 235/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.5002 - accuracy: 0.8228 - val_loss: 4.5521 - val_accuracy: 0.1500\n",
      "Epoch 236/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4986 - accuracy: 0.8228 - val_loss: 4.5757 - val_accuracy: 0.1500\n",
      "Epoch 237/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4972 - accuracy: 0.8228 - val_loss: 4.5993 - val_accuracy: 0.1500\n",
      "Epoch 238/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4957 - accuracy: 0.8354 - val_loss: 4.6226 - val_accuracy: 0.1500\n",
      "Epoch 239/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.4942 - accuracy: 0.8354 - val_loss: 4.6457 - val_accuracy: 0.1500\n",
      "Epoch 240/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4927 - accuracy: 0.8354 - val_loss: 4.6688 - val_accuracy: 0.1500\n",
      "Epoch 241/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4912 - accuracy: 0.8354 - val_loss: 4.6919 - val_accuracy: 0.1500\n",
      "Epoch 242/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4897 - accuracy: 0.8354 - val_loss: 4.7151 - val_accuracy: 0.1500\n",
      "Epoch 243/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4883 - accuracy: 0.8481 - val_loss: 4.7386 - val_accuracy: 0.1500\n",
      "Epoch 244/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4868 - accuracy: 0.8481 - val_loss: 4.7623 - val_accuracy: 0.1500\n",
      "Epoch 245/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4853 - accuracy: 0.8608 - val_loss: 4.7860 - val_accuracy: 0.1500\n",
      "Epoch 246/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4839 - accuracy: 0.8608 - val_loss: 4.8090 - val_accuracy: 0.1500\n",
      "Epoch 247/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4825 - accuracy: 0.8608 - val_loss: 4.8316 - val_accuracy: 0.1500\n",
      "Epoch 248/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4810 - accuracy: 0.8608 - val_loss: 4.8543 - val_accuracy: 0.1500\n",
      "Epoch 249/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4796 - accuracy: 0.8608 - val_loss: 4.8773 - val_accuracy: 0.1500\n",
      "Epoch 250/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4782 - accuracy: 0.8608 - val_loss: 4.9005 - val_accuracy: 0.1500\n",
      "Epoch 251/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4768 - accuracy: 0.8608 - val_loss: 4.9240 - val_accuracy: 0.1500\n",
      "Epoch 252/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4754 - accuracy: 0.8608 - val_loss: 4.9472 - val_accuracy: 0.1500\n",
      "Epoch 253/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.4740 - accuracy: 0.8608 - val_loss: 4.9704 - val_accuracy: 0.1500\n",
      "Epoch 254/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4726 - accuracy: 0.8608 - val_loss: 4.9938 - val_accuracy: 0.1500\n",
      "Epoch 255/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4712 - accuracy: 0.8608 - val_loss: 5.0172 - val_accuracy: 0.1500\n",
      "Epoch 256/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4699 - accuracy: 0.8608 - val_loss: 5.0405 - val_accuracy: 0.1500\n",
      "Epoch 257/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4685 - accuracy: 0.8608 - val_loss: 5.0647 - val_accuracy: 0.1500\n",
      "Epoch 258/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4671 - accuracy: 0.8608 - val_loss: 5.0893 - val_accuracy: 0.1500\n",
      "Epoch 259/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4658 - accuracy: 0.8608 - val_loss: 5.1138 - val_accuracy: 0.1500\n",
      "Epoch 260/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.4644 - accuracy: 0.8608 - val_loss: 5.1381 - val_accuracy: 0.1500\n",
      "Epoch 261/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4631 - accuracy: 0.8608 - val_loss: 5.1620 - val_accuracy: 0.1500\n",
      "Epoch 262/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4617 - accuracy: 0.8861 - val_loss: 5.1865 - val_accuracy: 0.1500\n",
      "Epoch 263/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4604 - accuracy: 0.8861 - val_loss: 5.2111 - val_accuracy: 0.1500\n",
      "Epoch 264/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4591 - accuracy: 0.8861 - val_loss: 5.2357 - val_accuracy: 0.1500\n",
      "Epoch 265/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.4578 - accuracy: 0.8861 - val_loss: 5.2599 - val_accuracy: 0.1500\n",
      "Epoch 266/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4565 - accuracy: 0.8861 - val_loss: 5.2841 - val_accuracy: 0.1500\n",
      "Epoch 267/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4551 - accuracy: 0.8861 - val_loss: 5.3081 - val_accuracy: 0.1500\n",
      "Epoch 268/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.4538 - accuracy: 0.8861 - val_loss: 5.3319 - val_accuracy: 0.1500\n",
      "Epoch 269/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4525 - accuracy: 0.8861 - val_loss: 5.3559 - val_accuracy: 0.1500\n",
      "Epoch 270/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4512 - accuracy: 0.8861 - val_loss: 5.3801 - val_accuracy: 0.1500\n",
      "Epoch 271/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4500 - accuracy: 0.8861 - val_loss: 5.4044 - val_accuracy: 0.1500\n",
      "Epoch 272/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4487 - accuracy: 0.8861 - val_loss: 5.4288 - val_accuracy: 0.1500\n",
      "Epoch 273/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4475 - accuracy: 0.8861 - val_loss: 5.4532 - val_accuracy: 0.1500\n",
      "Epoch 274/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4462 - accuracy: 0.8861 - val_loss: 5.4776 - val_accuracy: 0.1500\n",
      "Epoch 275/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4450 - accuracy: 0.8861 - val_loss: 5.5023 - val_accuracy: 0.1500\n",
      "Epoch 276/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.4438 - accuracy: 0.8861 - val_loss: 5.5269 - val_accuracy: 0.1500\n",
      "Epoch 277/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4426 - accuracy: 0.8861 - val_loss: 5.5516 - val_accuracy: 0.1500\n",
      "Epoch 278/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4414 - accuracy: 0.8861 - val_loss: 5.5762 - val_accuracy: 0.1500\n",
      "Epoch 279/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4402 - accuracy: 0.8861 - val_loss: 5.6006 - val_accuracy: 0.1500\n",
      "Epoch 280/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4390 - accuracy: 0.8861 - val_loss: 5.6248 - val_accuracy: 0.1500\n",
      "Epoch 281/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.4378 - accuracy: 0.8861 - val_loss: 5.6497 - val_accuracy: 0.1500\n",
      "Epoch 282/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4366 - accuracy: 0.8861 - val_loss: 5.6754 - val_accuracy: 0.1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4354 - accuracy: 0.8861 - val_loss: 5.7012 - val_accuracy: 0.1500\n",
      "Epoch 284/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4342 - accuracy: 0.8861 - val_loss: 5.7267 - val_accuracy: 0.1500\n",
      "Epoch 285/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4331 - accuracy: 0.8861 - val_loss: 5.7519 - val_accuracy: 0.1500\n",
      "Epoch 286/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4319 - accuracy: 0.8861 - val_loss: 5.7771 - val_accuracy: 0.1500\n",
      "Epoch 287/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4307 - accuracy: 0.8861 - val_loss: 5.8024 - val_accuracy: 0.1500\n",
      "Epoch 288/500\n",
      "79/79 [==============================] - 0s 37us/step - loss: 0.4296 - accuracy: 0.8861 - val_loss: 5.8287 - val_accuracy: 0.1500\n",
      "Epoch 289/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4284 - accuracy: 0.8861 - val_loss: 5.8549 - val_accuracy: 0.1500\n",
      "Epoch 290/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4272 - accuracy: 0.8861 - val_loss: 5.8808 - val_accuracy: 0.1500\n",
      "Epoch 291/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4261 - accuracy: 0.8861 - val_loss: 5.9069 - val_accuracy: 0.1500\n",
      "Epoch 292/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4250 - accuracy: 0.8861 - val_loss: 5.9335 - val_accuracy: 0.1500\n",
      "Epoch 293/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4239 - accuracy: 0.8861 - val_loss: 5.9598 - val_accuracy: 0.1500\n",
      "Epoch 294/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4227 - accuracy: 0.8861 - val_loss: 5.9862 - val_accuracy: 0.1500\n",
      "Epoch 295/500\n",
      "79/79 [==============================] - 0s 37us/step - loss: 0.4216 - accuracy: 0.8861 - val_loss: 6.0129 - val_accuracy: 0.1500\n",
      "Epoch 296/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.4205 - accuracy: 0.8861 - val_loss: 6.0402 - val_accuracy: 0.1500\n",
      "Epoch 297/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4194 - accuracy: 0.8861 - val_loss: 6.0673 - val_accuracy: 0.1500\n",
      "Epoch 298/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.4183 - accuracy: 0.8861 - val_loss: 6.0940 - val_accuracy: 0.1500\n",
      "Epoch 299/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4172 - accuracy: 0.8861 - val_loss: 6.1205 - val_accuracy: 0.1500\n",
      "Epoch 300/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4161 - accuracy: 0.8861 - val_loss: 6.1467 - val_accuracy: 0.1500\n",
      "Epoch 301/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4150 - accuracy: 0.8861 - val_loss: 6.1730 - val_accuracy: 0.1500\n",
      "Epoch 302/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.4140 - accuracy: 0.8861 - val_loss: 6.1995 - val_accuracy: 0.1500\n",
      "Epoch 303/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.4129 - accuracy: 0.8861 - val_loss: 6.2258 - val_accuracy: 0.1500\n",
      "Epoch 304/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4118 - accuracy: 0.8861 - val_loss: 6.2519 - val_accuracy: 0.1500\n",
      "Epoch 305/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4108 - accuracy: 0.8861 - val_loss: 6.2780 - val_accuracy: 0.1500\n",
      "Epoch 306/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4097 - accuracy: 0.8861 - val_loss: 6.3043 - val_accuracy: 0.1500\n",
      "Epoch 307/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.4087 - accuracy: 0.8861 - val_loss: 6.3302 - val_accuracy: 0.1500\n",
      "Epoch 308/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.4076 - accuracy: 0.8861 - val_loss: 6.3557 - val_accuracy: 0.1500\n",
      "Epoch 309/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4066 - accuracy: 0.8861 - val_loss: 6.3810 - val_accuracy: 0.1500\n",
      "Epoch 310/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.4055 - accuracy: 0.8861 - val_loss: 6.4062 - val_accuracy: 0.1500\n",
      "Epoch 311/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4045 - accuracy: 0.8861 - val_loss: 6.4319 - val_accuracy: 0.1500\n",
      "Epoch 312/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4034 - accuracy: 0.8861 - val_loss: 6.4585 - val_accuracy: 0.1500\n",
      "Epoch 313/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4024 - accuracy: 0.8861 - val_loss: 6.4854 - val_accuracy: 0.1500\n",
      "Epoch 314/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.4014 - accuracy: 0.8861 - val_loss: 6.5123 - val_accuracy: 0.1500\n",
      "Epoch 315/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.4003 - accuracy: 0.8987 - val_loss: 6.5387 - val_accuracy: 0.1500\n",
      "Epoch 316/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3993 - accuracy: 0.8987 - val_loss: 6.5650 - val_accuracy: 0.1500\n",
      "Epoch 317/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3983 - accuracy: 0.8861 - val_loss: 6.5913 - val_accuracy: 0.1500\n",
      "Epoch 318/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3973 - accuracy: 0.8861 - val_loss: 6.6176 - val_accuracy: 0.1500\n",
      "Epoch 319/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.3963 - accuracy: 0.8861 - val_loss: 6.6439 - val_accuracy: 0.1500\n",
      "Epoch 320/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.3953 - accuracy: 0.8861 - val_loss: 6.6705 - val_accuracy: 0.1500\n",
      "Epoch 321/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3942 - accuracy: 0.8987 - val_loss: 6.6972 - val_accuracy: 0.1500\n",
      "Epoch 322/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.3933 - accuracy: 0.8987 - val_loss: 6.7240 - val_accuracy: 0.1500\n",
      "Epoch 323/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3923 - accuracy: 0.8987 - val_loss: 6.7507 - val_accuracy: 0.1500\n",
      "Epoch 324/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3913 - accuracy: 0.8987 - val_loss: 6.7771 - val_accuracy: 0.1500\n",
      "Epoch 325/500\n",
      "79/79 [==============================] - 0s 23us/step - loss: 0.3903 - accuracy: 0.8987 - val_loss: 6.8031 - val_accuracy: 0.1500\n",
      "Epoch 326/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3893 - accuracy: 0.8987 - val_loss: 6.8294 - val_accuracy: 0.1500\n",
      "Epoch 327/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.3883 - accuracy: 0.8987 - val_loss: 6.8555 - val_accuracy: 0.1500\n",
      "Epoch 328/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3873 - accuracy: 0.8987 - val_loss: 6.8818 - val_accuracy: 0.1500\n",
      "Epoch 329/500\n",
      "79/79 [==============================] - 0s 37us/step - loss: 0.3863 - accuracy: 0.8987 - val_loss: 6.9086 - val_accuracy: 0.1500\n",
      "Epoch 330/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3853 - accuracy: 0.8987 - val_loss: 6.9355 - val_accuracy: 0.1500\n",
      "Epoch 331/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3844 - accuracy: 0.8987 - val_loss: 6.9619 - val_accuracy: 0.1500\n",
      "Epoch 332/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.3834 - accuracy: 0.8987 - val_loss: 6.9881 - val_accuracy: 0.1500\n",
      "Epoch 333/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3825 - accuracy: 0.8987 - val_loss: 7.0144 - val_accuracy: 0.1500\n",
      "Epoch 334/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3815 - accuracy: 0.8987 - val_loss: 7.0391 - val_accuracy: 0.1500\n",
      "Epoch 335/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3805 - accuracy: 0.9114 - val_loss: 7.0630 - val_accuracy: 0.1500\n",
      "Epoch 336/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.3796 - accuracy: 0.9114 - val_loss: 7.0866 - val_accuracy: 0.1500\n",
      "Epoch 337/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3786 - accuracy: 0.9114 - val_loss: 7.1106 - val_accuracy: 0.1500\n",
      "Epoch 338/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.3777 - accuracy: 0.9114 - val_loss: 7.1344 - val_accuracy: 0.1500\n",
      "Epoch 339/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3767 - accuracy: 0.9114 - val_loss: 7.1578 - val_accuracy: 0.1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 340/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3757 - accuracy: 0.9114 - val_loss: 7.1817 - val_accuracy: 0.1500\n",
      "Epoch 341/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3748 - accuracy: 0.9241 - val_loss: 7.2054 - val_accuracy: 0.1500\n",
      "Epoch 342/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3738 - accuracy: 0.9241 - val_loss: 7.2290 - val_accuracy: 0.1500\n",
      "Epoch 343/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.3729 - accuracy: 0.9241 - val_loss: 7.2527 - val_accuracy: 0.1500\n",
      "Epoch 344/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3720 - accuracy: 0.9241 - val_loss: 7.2765 - val_accuracy: 0.1500\n",
      "Epoch 345/500\n",
      "79/79 [==============================] - 0s 37us/step - loss: 0.3710 - accuracy: 0.9241 - val_loss: 7.3003 - val_accuracy: 0.1500\n",
      "Epoch 346/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.3701 - accuracy: 0.9241 - val_loss: 7.3238 - val_accuracy: 0.1500\n",
      "Epoch 347/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.3692 - accuracy: 0.9241 - val_loss: 7.3469 - val_accuracy: 0.1500\n",
      "Epoch 348/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3682 - accuracy: 0.9241 - val_loss: 7.3698 - val_accuracy: 0.1500\n",
      "Epoch 349/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3673 - accuracy: 0.9241 - val_loss: 7.3929 - val_accuracy: 0.1500\n",
      "Epoch 350/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3664 - accuracy: 0.9241 - val_loss: 7.4165 - val_accuracy: 0.1500\n",
      "Epoch 351/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3654 - accuracy: 0.9241 - val_loss: 7.4406 - val_accuracy: 0.1500\n",
      "Epoch 352/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.3645 - accuracy: 0.9241 - val_loss: 7.4646 - val_accuracy: 0.1500\n",
      "Epoch 353/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3636 - accuracy: 0.9241 - val_loss: 7.4888 - val_accuracy: 0.1500\n",
      "Epoch 354/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.3627 - accuracy: 0.9241 - val_loss: 7.5132 - val_accuracy: 0.1500\n",
      "Epoch 355/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3617 - accuracy: 0.9241 - val_loss: 7.5377 - val_accuracy: 0.1500\n",
      "Epoch 356/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.3608 - accuracy: 0.9241 - val_loss: 7.5623 - val_accuracy: 0.1500\n",
      "Epoch 357/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3599 - accuracy: 0.9241 - val_loss: 7.5868 - val_accuracy: 0.1500\n",
      "Epoch 358/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3590 - accuracy: 0.9241 - val_loss: 7.6108 - val_accuracy: 0.1500\n",
      "Epoch 359/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.3581 - accuracy: 0.9241 - val_loss: 7.6346 - val_accuracy: 0.1500\n",
      "Epoch 360/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.3572 - accuracy: 0.9241 - val_loss: 7.6582 - val_accuracy: 0.1500\n",
      "Epoch 361/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3563 - accuracy: 0.9241 - val_loss: 7.6824 - val_accuracy: 0.1500\n",
      "Epoch 362/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3554 - accuracy: 0.9241 - val_loss: 7.7068 - val_accuracy: 0.1500\n",
      "Epoch 363/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3544 - accuracy: 0.9241 - val_loss: 7.7314 - val_accuracy: 0.1500\n",
      "Epoch 364/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3536 - accuracy: 0.9241 - val_loss: 7.7563 - val_accuracy: 0.1500\n",
      "Epoch 365/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.3527 - accuracy: 0.9241 - val_loss: 7.7811 - val_accuracy: 0.1500\n",
      "Epoch 366/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3518 - accuracy: 0.9241 - val_loss: 7.8059 - val_accuracy: 0.1500\n",
      "Epoch 367/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.3509 - accuracy: 0.9241 - val_loss: 7.8308 - val_accuracy: 0.1500\n",
      "Epoch 368/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.3500 - accuracy: 0.9241 - val_loss: 7.8557 - val_accuracy: 0.1500\n",
      "Epoch 369/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3491 - accuracy: 0.9241 - val_loss: 7.8806 - val_accuracy: 0.1500\n",
      "Epoch 370/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.3482 - accuracy: 0.9241 - val_loss: 7.9054 - val_accuracy: 0.1500\n",
      "Epoch 371/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.3473 - accuracy: 0.9241 - val_loss: 7.9294 - val_accuracy: 0.1500\n",
      "Epoch 372/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3464 - accuracy: 0.9241 - val_loss: 7.9536 - val_accuracy: 0.1500\n",
      "Epoch 373/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3455 - accuracy: 0.9241 - val_loss: 7.9782 - val_accuracy: 0.1500\n",
      "Epoch 374/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3446 - accuracy: 0.9241 - val_loss: 8.0034 - val_accuracy: 0.1500\n",
      "Epoch 375/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3437 - accuracy: 0.9241 - val_loss: 8.0287 - val_accuracy: 0.1500\n",
      "Epoch 376/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3428 - accuracy: 0.9241 - val_loss: 8.0538 - val_accuracy: 0.1500\n",
      "Epoch 377/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3419 - accuracy: 0.9241 - val_loss: 8.0789 - val_accuracy: 0.1500\n",
      "Epoch 378/500\n",
      "79/79 [==============================] - 0s 50us/step - loss: 0.3410 - accuracy: 0.9241 - val_loss: 8.1029 - val_accuracy: 0.1500\n",
      "Epoch 379/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3401 - accuracy: 0.9241 - val_loss: 8.1253 - val_accuracy: 0.1500\n",
      "Epoch 380/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3392 - accuracy: 0.9241 - val_loss: 8.1478 - val_accuracy: 0.1500\n",
      "Epoch 381/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.3383 - accuracy: 0.9241 - val_loss: 8.1705 - val_accuracy: 0.1500\n",
      "Epoch 382/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3374 - accuracy: 0.9241 - val_loss: 8.1930 - val_accuracy: 0.1500\n",
      "Epoch 383/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3365 - accuracy: 0.9241 - val_loss: 8.2157 - val_accuracy: 0.1500\n",
      "Epoch 384/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.3357 - accuracy: 0.9241 - val_loss: 8.2386 - val_accuracy: 0.1500\n",
      "Epoch 385/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.3348 - accuracy: 0.9241 - val_loss: 8.2618 - val_accuracy: 0.1500\n",
      "Epoch 386/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3339 - accuracy: 0.9241 - val_loss: 8.2850 - val_accuracy: 0.1500\n",
      "Epoch 387/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.3330 - accuracy: 0.9241 - val_loss: 8.3084 - val_accuracy: 0.1500\n",
      "Epoch 388/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3321 - accuracy: 0.9241 - val_loss: 8.3316 - val_accuracy: 0.1500\n",
      "Epoch 389/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.3312 - accuracy: 0.9241 - val_loss: 8.3523 - val_accuracy: 0.1500\n",
      "Epoch 390/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3304 - accuracy: 0.9241 - val_loss: 8.3720 - val_accuracy: 0.1500\n",
      "Epoch 391/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3295 - accuracy: 0.9241 - val_loss: 8.3913 - val_accuracy: 0.1500\n",
      "Epoch 392/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3287 - accuracy: 0.9241 - val_loss: 8.4111 - val_accuracy: 0.1500\n",
      "Epoch 393/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3278 - accuracy: 0.9241 - val_loss: 8.4313 - val_accuracy: 0.1500\n",
      "Epoch 394/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.3269 - accuracy: 0.9241 - val_loss: 8.4521 - val_accuracy: 0.1500\n",
      "Epoch 395/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3261 - accuracy: 0.9241 - val_loss: 8.4731 - val_accuracy: 0.1500\n",
      "Epoch 396/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3252 - accuracy: 0.9241 - val_loss: 8.4942 - val_accuracy: 0.1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 397/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.3244 - accuracy: 0.9241 - val_loss: 8.5148 - val_accuracy: 0.1500\n",
      "Epoch 398/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3235 - accuracy: 0.9241 - val_loss: 8.5352 - val_accuracy: 0.1500\n",
      "Epoch 399/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3227 - accuracy: 0.9241 - val_loss: 8.5553 - val_accuracy: 0.1500\n",
      "Epoch 400/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.3218 - accuracy: 0.9241 - val_loss: 8.5753 - val_accuracy: 0.1500\n",
      "Epoch 401/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3210 - accuracy: 0.9241 - val_loss: 8.5950 - val_accuracy: 0.1500\n",
      "Epoch 402/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3201 - accuracy: 0.9241 - val_loss: 8.6147 - val_accuracy: 0.1500\n",
      "Epoch 403/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3193 - accuracy: 0.9241 - val_loss: 8.6350 - val_accuracy: 0.1500\n",
      "Epoch 404/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3184 - accuracy: 0.9241 - val_loss: 8.6553 - val_accuracy: 0.1500\n",
      "Epoch 405/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3176 - accuracy: 0.9241 - val_loss: 8.6759 - val_accuracy: 0.1500\n",
      "Epoch 406/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.3168 - accuracy: 0.9241 - val_loss: 8.6972 - val_accuracy: 0.1500\n",
      "Epoch 407/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3159 - accuracy: 0.9241 - val_loss: 8.7180 - val_accuracy: 0.1500\n",
      "Epoch 408/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3151 - accuracy: 0.9241 - val_loss: 8.7386 - val_accuracy: 0.1500\n",
      "Epoch 409/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.3142 - accuracy: 0.9241 - val_loss: 8.7590 - val_accuracy: 0.1500\n",
      "Epoch 410/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3134 - accuracy: 0.9241 - val_loss: 8.7790 - val_accuracy: 0.1500\n",
      "Epoch 411/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.3126 - accuracy: 0.9241 - val_loss: 8.7992 - val_accuracy: 0.1500\n",
      "Epoch 412/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.3117 - accuracy: 0.9241 - val_loss: 8.8197 - val_accuracy: 0.1500\n",
      "Epoch 413/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.3109 - accuracy: 0.9241 - val_loss: 8.8399 - val_accuracy: 0.1500\n",
      "Epoch 414/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3101 - accuracy: 0.9241 - val_loss: 8.8600 - val_accuracy: 0.1500\n",
      "Epoch 415/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3093 - accuracy: 0.9241 - val_loss: 8.8798 - val_accuracy: 0.1500\n",
      "Epoch 416/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3085 - accuracy: 0.9241 - val_loss: 8.8992 - val_accuracy: 0.1500\n",
      "Epoch 417/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.3076 - accuracy: 0.9241 - val_loss: 8.9185 - val_accuracy: 0.1500\n",
      "Epoch 418/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3068 - accuracy: 0.9241 - val_loss: 8.9373 - val_accuracy: 0.1500\n",
      "Epoch 419/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.3060 - accuracy: 0.9241 - val_loss: 8.9559 - val_accuracy: 0.1500\n",
      "Epoch 420/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3052 - accuracy: 0.9241 - val_loss: 8.9744 - val_accuracy: 0.1500\n",
      "Epoch 421/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.3044 - accuracy: 0.9241 - val_loss: 8.9936 - val_accuracy: 0.1500\n",
      "Epoch 422/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3036 - accuracy: 0.9241 - val_loss: 9.0132 - val_accuracy: 0.1500\n",
      "Epoch 423/500\n",
      "79/79 [==============================] - 0s 24us/step - loss: 0.3027 - accuracy: 0.9241 - val_loss: 9.0322 - val_accuracy: 0.1500\n",
      "Epoch 424/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3019 - accuracy: 0.9367 - val_loss: 9.0512 - val_accuracy: 0.1500\n",
      "Epoch 425/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.3011 - accuracy: 0.9367 - val_loss: 9.0705 - val_accuracy: 0.1500\n",
      "Epoch 426/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.3003 - accuracy: 0.9367 - val_loss: 9.0895 - val_accuracy: 0.1500\n",
      "Epoch 427/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2995 - accuracy: 0.9367 - val_loss: 9.1082 - val_accuracy: 0.1500\n",
      "Epoch 428/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.2987 - accuracy: 0.9367 - val_loss: 9.1267 - val_accuracy: 0.1500\n",
      "Epoch 429/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2979 - accuracy: 0.9367 - val_loss: 9.1451 - val_accuracy: 0.1500\n",
      "Epoch 430/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2971 - accuracy: 0.9367 - val_loss: 9.1636 - val_accuracy: 0.1500\n",
      "Epoch 431/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2963 - accuracy: 0.9367 - val_loss: 9.1816 - val_accuracy: 0.1500\n",
      "Epoch 432/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.2955 - accuracy: 0.9367 - val_loss: 9.2001 - val_accuracy: 0.1500\n",
      "Epoch 433/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2947 - accuracy: 0.9367 - val_loss: 9.2188 - val_accuracy: 0.1500\n",
      "Epoch 434/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2939 - accuracy: 0.9494 - val_loss: 9.2376 - val_accuracy: 0.1500\n",
      "Epoch 435/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2931 - accuracy: 0.9494 - val_loss: 9.2568 - val_accuracy: 0.1500\n",
      "Epoch 436/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2923 - accuracy: 0.9494 - val_loss: 9.2756 - val_accuracy: 0.1500\n",
      "Epoch 437/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2915 - accuracy: 0.9494 - val_loss: 9.2937 - val_accuracy: 0.1500\n",
      "Epoch 438/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2907 - accuracy: 0.9494 - val_loss: 9.3117 - val_accuracy: 0.1500\n",
      "Epoch 439/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2900 - accuracy: 0.9494 - val_loss: 9.3298 - val_accuracy: 0.1500\n",
      "Epoch 440/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.2892 - accuracy: 0.9494 - val_loss: 9.3481 - val_accuracy: 0.1500\n",
      "Epoch 441/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.2884 - accuracy: 0.9494 - val_loss: 9.3664 - val_accuracy: 0.1500\n",
      "Epoch 442/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2877 - accuracy: 0.9494 - val_loss: 9.3849 - val_accuracy: 0.1500\n",
      "Epoch 443/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.2869 - accuracy: 0.9494 - val_loss: 9.4038 - val_accuracy: 0.1500\n",
      "Epoch 444/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2861 - accuracy: 0.9494 - val_loss: 9.4227 - val_accuracy: 0.1500\n",
      "Epoch 445/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.2854 - accuracy: 0.9494 - val_loss: 9.4398 - val_accuracy: 0.1500\n",
      "Epoch 446/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2846 - accuracy: 0.9494 - val_loss: 9.4561 - val_accuracy: 0.1500\n",
      "Epoch 447/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2839 - accuracy: 0.9494 - val_loss: 9.4719 - val_accuracy: 0.1500\n",
      "Epoch 448/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2831 - accuracy: 0.9494 - val_loss: 9.4877 - val_accuracy: 0.1500\n",
      "Epoch 449/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.2824 - accuracy: 0.9494 - val_loss: 9.5038 - val_accuracy: 0.1500\n",
      "Epoch 450/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2817 - accuracy: 0.9494 - val_loss: 9.5199 - val_accuracy: 0.1500\n",
      "Epoch 451/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.2809 - accuracy: 0.9494 - val_loss: 9.5357 - val_accuracy: 0.1500\n",
      "Epoch 452/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2802 - accuracy: 0.9494 - val_loss: 9.5511 - val_accuracy: 0.1500\n",
      "Epoch 453/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.2794 - accuracy: 0.9494 - val_loss: 9.5667 - val_accuracy: 0.1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 454/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2787 - accuracy: 0.9494 - val_loss: 9.5826 - val_accuracy: 0.1500\n",
      "Epoch 455/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.2780 - accuracy: 0.9494 - val_loss: 9.5984 - val_accuracy: 0.1500\n",
      "Epoch 456/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.2772 - accuracy: 0.9494 - val_loss: 9.6140 - val_accuracy: 0.1500\n",
      "Epoch 457/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.2765 - accuracy: 0.9494 - val_loss: 9.6293 - val_accuracy: 0.1500\n",
      "Epoch 458/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2758 - accuracy: 0.9494 - val_loss: 9.6445 - val_accuracy: 0.1500\n",
      "Epoch 459/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.2751 - accuracy: 0.9494 - val_loss: 9.6601 - val_accuracy: 0.1500\n",
      "Epoch 460/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.2745 - accuracy: 0.9494 - val_loss: 9.6762 - val_accuracy: 0.1500\n",
      "Epoch 461/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2738 - accuracy: 0.9494 - val_loss: 9.6925 - val_accuracy: 0.1500\n",
      "Epoch 462/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2731 - accuracy: 0.9494 - val_loss: 9.7086 - val_accuracy: 0.1500\n",
      "Epoch 463/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2724 - accuracy: 0.9494 - val_loss: 9.7247 - val_accuracy: 0.1500\n",
      "Epoch 464/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.2717 - accuracy: 0.9494 - val_loss: 9.7406 - val_accuracy: 0.1500\n",
      "Epoch 465/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2710 - accuracy: 0.9494 - val_loss: 9.7563 - val_accuracy: 0.1500\n",
      "Epoch 466/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.2704 - accuracy: 0.9494 - val_loss: 9.7717 - val_accuracy: 0.1500\n",
      "Epoch 467/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.2698 - accuracy: 0.9494 - val_loss: 9.7871 - val_accuracy: 0.1500\n",
      "Epoch 468/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.2691 - accuracy: 0.9494 - val_loss: 9.8028 - val_accuracy: 0.1500\n",
      "Epoch 469/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.2685 - accuracy: 0.9494 - val_loss: 9.8187 - val_accuracy: 0.1500\n",
      "Epoch 470/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2678 - accuracy: 0.9494 - val_loss: 9.8346 - val_accuracy: 0.1500\n",
      "Epoch 471/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.2672 - accuracy: 0.9494 - val_loss: 9.8504 - val_accuracy: 0.1500\n",
      "Epoch 472/500\n",
      "79/79 [==============================] - 0s 37us/step - loss: 0.2666 - accuracy: 0.9494 - val_loss: 9.8656 - val_accuracy: 0.1500\n",
      "Epoch 473/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.2659 - accuracy: 0.9620 - val_loss: 9.8804 - val_accuracy: 0.1500\n",
      "Epoch 474/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.2653 - accuracy: 0.9620 - val_loss: 9.8946 - val_accuracy: 0.1500\n",
      "Epoch 475/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2647 - accuracy: 0.9620 - val_loss: 9.9090 - val_accuracy: 0.1500\n",
      "Epoch 476/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.2640 - accuracy: 0.9620 - val_loss: 9.9241 - val_accuracy: 0.1500\n",
      "Epoch 477/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2634 - accuracy: 0.9620 - val_loss: 9.9398 - val_accuracy: 0.1500\n",
      "Epoch 478/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2628 - accuracy: 0.9620 - val_loss: 9.9550 - val_accuracy: 0.1500\n",
      "Epoch 479/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2622 - accuracy: 0.9620 - val_loss: 9.9696 - val_accuracy: 0.1500\n",
      "Epoch 480/500\n",
      "79/79 [==============================] - 0s 26us/step - loss: 0.2616 - accuracy: 0.9620 - val_loss: 9.9841 - val_accuracy: 0.1500\n",
      "Epoch 481/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2610 - accuracy: 0.9620 - val_loss: 9.9984 - val_accuracy: 0.1500\n",
      "Epoch 482/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2603 - accuracy: 0.9620 - val_loss: 10.0120 - val_accuracy: 0.1500\n",
      "Epoch 483/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.2597 - accuracy: 0.9620 - val_loss: 10.0254 - val_accuracy: 0.1500\n",
      "Epoch 484/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2591 - accuracy: 0.9620 - val_loss: 10.0392 - val_accuracy: 0.1500\n",
      "Epoch 485/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2586 - accuracy: 0.9620 - val_loss: 10.0529 - val_accuracy: 0.1500\n",
      "Epoch 486/500\n",
      "79/79 [==============================] - 0s 12us/step - loss: 0.2580 - accuracy: 0.9620 - val_loss: 10.0670 - val_accuracy: 0.1500\n",
      "Epoch 487/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.2574 - accuracy: 0.9620 - val_loss: 10.0812 - val_accuracy: 0.1500\n",
      "Epoch 488/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2568 - accuracy: 0.9620 - val_loss: 10.0954 - val_accuracy: 0.1500\n",
      "Epoch 489/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2562 - accuracy: 0.9620 - val_loss: 10.1098 - val_accuracy: 0.1500\n",
      "Epoch 490/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2556 - accuracy: 0.9620 - val_loss: 10.1242 - val_accuracy: 0.1500\n",
      "Epoch 491/500\n",
      "79/79 [==============================] - 0s 38us/step - loss: 0.2550 - accuracy: 0.9620 - val_loss: 10.1386 - val_accuracy: 0.1500\n",
      "Epoch 492/500\n",
      "79/79 [==============================] - 0s 13us/step - loss: 0.2545 - accuracy: 0.9620 - val_loss: 10.1526 - val_accuracy: 0.1500\n",
      "Epoch 493/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2539 - accuracy: 0.9620 - val_loss: 10.1662 - val_accuracy: 0.1500\n",
      "Epoch 494/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2533 - accuracy: 0.9620 - val_loss: 10.1799 - val_accuracy: 0.1500\n",
      "Epoch 495/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2527 - accuracy: 0.9620 - val_loss: 10.1925 - val_accuracy: 0.1500\n",
      "Epoch 496/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2522 - accuracy: 0.9620 - val_loss: 10.2049 - val_accuracy: 0.1500\n",
      "Epoch 497/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2516 - accuracy: 0.9620 - val_loss: 10.2171 - val_accuracy: 0.1500\n",
      "Epoch 498/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2511 - accuracy: 0.9620 - val_loss: 10.2292 - val_accuracy: 0.1500\n",
      "Epoch 499/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2505 - accuracy: 0.9620 - val_loss: 10.2414 - val_accuracy: 0.1500\n",
      "Epoch 500/500\n",
      "79/79 [==============================] - 0s 25us/step - loss: 0.2499 - accuracy: 0.9620 - val_loss: 10.2538 - val_accuracy: 0.1500\n"
     ]
    }
   ],
   "source": [
    "# delta Price!!!!!!!!!!!作為input\n",
    "with open('001_b_1110_1_1_p1.csv', newline='') as csvfile1:\n",
    "    data1 = pd.read_csv(csvfile1)\n",
    "with open('002_b_1110_1_1_p2.csv', newline='') as csvfile2:\n",
    "    data2 = pd.read_csv(csvfile2)\n",
    "X = data1.loc[:,['p1Cash','StockPrice','p1TotalAsset']]\n",
    "X['p2TotalAsset'] = data2.loc[:,['p2TotalAsset']]\n",
    "X['p1ChechHistory'] = pd.get_dummies(data1.loc[:,'p1ChechHistory'])['yes']\n",
    "X_1_101 = X[1:101]\n",
    "X_1_101 = X_1_101.reset_index()\n",
    "X_0_100 = X[0:100]\n",
    "X_0_100 = X_0_100.rename(columns = {'p1Cash':'pre_p1Cash','StockPrice':'pre_StockPrice','p1TotalAsset':'pre_p1TotalAsset',\n",
    "                                   'p2TotalAsset':'pre_p2TotalAsset','p1ChechHistory':'pre_p1ChechHistory'}, inplace = False)\n",
    "X = pd.concat([X_1_101,X_0_100], axis=1)\n",
    "X = X.drop(['index'], axis = 1)\n",
    "X['delta_Price'] = X['StockPrice']-X['pre_StockPrice']\n",
    "X = X[0:99]\n",
    "\n",
    "X = preprocessing.scale(X)\n",
    "\n",
    "Y = data1.loc[:,'p1Decision']\n",
    "Y_dum = pd.get_dummies(Y)\n",
    "Y = Y_dum[1:100]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(80, input_dim = 11, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "test = model.fit(X,Y, epochs = 500, batch_size = 80, validation_split = 0.2, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3de3xV1Zn/8c+TOyGBQMJNEggCKqiAiJd6qfcbtdqptmjbaUtt+bWjrVNrW/2No7XtzOj8ehmtTi0dsdpardparaNV66XVVkXAgAIiSLmE+y0Jt9yf3x97n3gIJxAgJzs5+/t+vc7rnL32PjvPCuE8Z62191rm7oiISHxlRR2AiIhES4lARCTmlAhERGJOiUBEJOaUCEREYk6JQEQk5pQIJBbMrNLM3MxyOnHs583s1e6IS6QnUCKQHsfMVphZo5mVtSuvCj/MK6OJTCQzKRFIT/V34MrEhpkdC/SJLpyeoTMtGpEDpUQgPdUvgc8mbX8OeCD5ADPrb2YPmNkmM1tpZjeZWVa4L9vMfmBmm81sOfCRFO+918zWmdkaM/u+mWV3JjAze9TM1ptZrZn9xcyOTtrXx8x+GMZTa2avmlmfcN9pZvY3M6sxs9Vm9vmw/GUz+2LSOfbomgpbQVeb2VJgaVh2R3iOOjOba2anJx2fbWb/18zeN7Pt4f4KM7vbzH7Yri5/MLN/7ky9JXMpEUhP9TrQz8zGhR/Q04BftTvmJ0B/4HDgDILEMT3c9yXgYuA4YApwebv33g80A2PCY84HvkjnPAOMBQYD84AHk/b9ADgeOAUYCHwLaDWzEeH7fgIMAiYBVZ38eQAfA04Cxofbb4bnGAj8GnjUzArCfdcRtKamAv2ALwC7wjpfmZQsy4BzgIcOIA7JRO6uhx496gGsAM4FbgL+A7gQeB7IARyoBLKBBmB80vv+D/By+PpF4MtJ+84P35sDDAnf2ydp/5XAS+HrzwOvdjLWkvC8/Qm+WO0GJqY47kbg8Q7O8TLwxaTtPX5+eP6z9xPHtsTPBZYAl3Zw3GLgvPD1NcDTUf976xH9Q/2N0pP9EvgLMIp23UJAGZAHrEwqWwkMD18fBqxuty9hJJALrDOzRFlWu+NTClsn/wZ8guCbfWtSPPlAAfB+irdWdFDeWXvEZmbfIGjBHEaQKPqFMezvZ90PfIYgsX4GuOMQYpIMoa4h6bHcfSXBoPFU4Hftdm8Gmgg+1BNGAGvC1+sIPhCT9yWsJmgRlLl7Sfjo5+5Hs3+fAi4laLH0J2idAFgYUz0wOsX7VndQDrATKEzaHprimLZpgsPxgG8DnwQGuHsJUBvGsL+f9SvgUjObCIwDft/BcRIjSgTS011F0C2yM7nQ3VuAR4B/M7NiMxtJ0DeeGEd4BPiamZWb2QDghqT3rgOeA35oZv3MLMvMRpvZGZ2Ip5ggiWwh+PD+96TztgKzgB+Z2WHhoO2HzCyfYBzhXDP7pJnlmFmpmU0K31oFfNzMCs1sTFjn/cXQDGwCcszsZoIWQcL/AN8zs7EWmGBmpWGM1QTjC78EfuvuuztRZ8lwSgTSo7n7++4+p4PdXyX4Nr0ceJVg0HRWuO/nwLPAfIIB3fYtis8SdC0tIuhffwwY1omQHiDoZloTvvf1dvuvB94m+LDdCtwOZLn7KoKWzTfC8ipgYvieHwONwAaCrpsH2bdnCQae3wtjqWfPrqMfESTC54A64F72vPT2fuBYgmQggrlrYRqRODGzDxO0nCrDVozEnFoEIjFiZrnAtcD/KAlIghKBSEyY2TighqAL7L8iDkd6kLQlAjObZWYbzeydDvabmd1pZsvMbIGZTU5XLCIC7r7Y3fu6+ynuXhd1PNJzpLNF8AuCG4E6chHB3ZljgRnAT9MYi4iIdCBtN5S5+1/2M0vkpcADHoxWv25mJWY2LLy0r0NlZWVeWbmv04qISHtz587d7O6DUu2L8s7i4ex5yVt1WLbPRFBZWcmcOR1dTSgiIqmY2cqO9kU5WGwpylJey2pmM8xsjpnN2bRpU5rDEhGJlygTQTV7TgFQDqxNdaC7z3T3Ke4+ZdCglC0bERE5SFEmgieBz4ZXD50M1O5vfEBERLpe2sYIzOwh4EygzMyqgVsIZnzE3e8Bnia45X4ZwVzp01Ofaf+ampqorq6mvr7+UMPuNQoKCigvLyc3NzfqUESkl0vnVUNX7me/A1d3xc+qrq6muLiYyspKkqYVzljuzpYtW6iurmbUqFFRhyMivVxG3FlcX19PaWlpLJIAgJlRWloaqxaQiKRPRiQCIDZJICFu9RWR9NEKZSIiabZ80w5+X7UWDnG253PGDWFiRUkXRfUBJYIusGXLFs455xwA1q9fT3Z2NonLXGfPnk1eXt5+zzF9+nRuuOEGjjzyyLTGKiLd764Xl/G7t9ZwqA35wf0KlAh6qtLSUqqqqgD4zne+Q1FREddff/0exyQWic7KSt0bd99996U9ThGJRlV1DeeNH8LPPzsl6lBSUiJIo2XLlvGxj32M0047jTfeeIOnnnqKW2+9lXnz5rF7926mTZvGzTffDMBpp53GXXfdxTHHHENZWRlf/vKXeeaZZygsLOSJJ55g8ODBEddGJHNt3F7PXS8uo7G565docIflm3by8eOGd/m5u0rGJYJb/7CQRWu7dobd8Yf145aPdmZd870tWrSI++67j3vuuQeA2267jYEDB9Lc3MxZZ53F5Zdfzvjx4/d4T21tLWeccQa33XYb1113HbNmzeKGG25IdXoR6QJPVq3lgddWMrg4/5C7b1IZMbCQs48a0vUn7iIZlwh6mtGjR3PCCSe0bT/00EPce++9NDc3s3btWhYtWrRXIujTpw8XXXQRAMcffzyvvPJKt8YsEjfzq2sZXtKHv95wdtShRCLjEsHBfnNPl759+7a9Xrp0KXfccQezZ8+mpKSEz3zmMynvBUgeXM7Ozqa5ublbYhXJdIvW1vHjP71Ha+ueV+/MXrGV08eWRRRV9DLmPoLeoK6ujuLiYvr168e6det49tlnow5JJFYenbual97dyIbt9Xs8RpX15fLjy6MOLzIZ1yLoySZPnsz48eM55phjOPzwwzn11FOjDkkkVuavruG4ESU8+uVTog6lRzE/xBscutuUKVO8/cI0ixcvZty4cRFFFJ241lu6V1NLK1/51Tw21PX+KU0Wr6vj86dUctPF4/d/cIYxs7nunvL6VbUIRGSfFq2t40+LNzCpooSBffd/c2RPNrT/YC6LcRdQR5QIRGSf5lfXAHD3pyczvKRPxNFIOigRiMhefvDsEh6dGywpvr2+mbKifA7rXxBxVJIuSgQispfH5lZTXJDLlJEDAPjQ6PhM8x5HSgQisocNdfWsr6vn5g+P5wunaeGjOFAiEMlw7s6ld/+VFZt38vx1Z7BtVyMf/++/sbuppYPjg+eJFf27MUqJkhJBF+iKaagBZs2axdSpUxk6dGjaYpX4WV9Xz4LqWgBeX76FjXUN7Gps4StnjiY3K3V3T//CPI6rGNCdYUqElAi6QGemoe6MWbNmMXnyZCWCDFRX30RDU9fPbNkZf122pe317L9vZdP2BoaX9OHbFx4VSTzS8ygRpNn999/P3XffTWNjI6eccgp33XUXra2tTJ8+naqqKtydGTNmMGTIEKqqqpg2bRp9+vQ5oJaE9GyL1tZx8U9eoTXCezfzsrMYN6yYB99YBcBHJgyLLhjpcTIvETxzA6x/u2vPOfRYuOi2A37bO++8w+OPP87f/vY3cnJymDFjBg8//DCjR49m8+bNvP12EGdNTQ0lJSX85Cc/4a677mLSpEldG79EasmGOlodvn7uEQwsiia5jy7ry+B++by2fCsAZx05KJI4pGfKvETQg/zpT3/izTffZMqU4K7u3bt3U1FRwQUXXMCSJUu49tprmTp1Kueff37EkUo6ra9tAOCq00dRlB/tf7kxg4sj/fnSM2VeIjiIb+7p4u584Qtf4Hvf+95e+xYsWMAzzzzDnXfeyW9/+1tmzpwZQYTSHTbU1VOUnxN5EhDpiKahTqNzzz2XRx55hM2bNwPB1UWrVq1i06ZNuDuf+MQn2pauBCguLmb79u1RhixpsKGuniH98qMOQ6RD+oqSRsceeyy33HIL5557Lq2treTm5nLPPfeQnZ3NVVddhbtjZtx+++0ATJ8+nS9+8YsaLO4lanY18tbqmv0et2zjDoZqegbpwTQNdS8W13r3FF//TRWPv7WmU8d++qQR/Ns/HJvmiEQ6pmmoRdJg7sptnD62jOvOO2K/xx41tF83RCRycJQIRA7CX97bxKqtu/jUSSM4boTuwJXeLWMGi3tbF9ehilt9e5rrHgnuJP/Q4aURRyJy6DIiERQUFLBly5bYfDi6O1u2bKGgQAOQUVhfW8/mHY187ewxTKwoiTockUOWEV1D5eXlVFdXs2nTpqhD6TYFBQWUl2vJve700rsbWbi2lhVbdgFw1lGDI45IpGtkRCLIzc1l1CjNmy7p09LqXP3reexqDKZuHtqvgHHDNAAsmSEjEoFIui3duJ1djS384BMTuXTSYWSbkdXBFM4ivY0SgUiSqtU1/G5e9V7lie6gySNKyM3OiKE1kTZKBCJJ7npxKS8v2URxwd7/NY4fOYDK0r4RRCWSXkoEIiF3p2p1LZdMOowffVJTgUt8pLWNa2YXmtkSM1tmZjek2D/CzF4ys7fMbIGZTU1nPCKptLY633tqEV96YC6bdzQwSZeESsykLRGYWTZwN3ARMB640szGtzvsJuARdz8OuAL473TFI9KR5Zt3cu+rf2fxujomVpRw1pG6LFTiJZ1dQycCy9x9OYCZPQxcCixKOsaBxDV4/YG1aYxHJKUF1cEMor+YfgJjh2jhFomfdCaC4cDqpO1q4KR2x3wHeM7Mvgr0Bc5NdSIzmwHMABgxYkSXByrx09DcwrUPVbFpRwNra3bTNy+bwwcVRR2WSCTSOUaQ6iLr9nNAXAn8wt3LganAL81sr5jcfaa7T3H3KYMGaa1VOXTvrKnljwvX09jcyuhBRVxz9liydV+AxFQ6WwTVQEXSdjl7d/1cBVwI4O6vmVkBUAZsTGNcIlStrgXg3s9NYXA/zdkk8ZbORPAmMNbMRgFrCAaDP9XumFXAOcAvzGwcUADEZ8Ig6VY/eHYJT8wPFpKp2dnEsP4FSgIipDERuHuzmV0DPAtkA7PcfaGZfReY4+5PAt8Afm5mXyfoNvq8x2UKUelW7s7Db66mf58cJpYHl4d++Ah1M4pAmm8oc/engafbld2c9HoRcGo6YxABWFtbz+YdDXztnDF89kOVUYcj0qPozmLJCO+ur2Paz16nvqkl5f7WsKE5oVw3i4m0p0QgGWFBdS21u5v4zMkj6Juf+s96YGEeE4b37+bIRHo+JQLJCBtq6wG46SPjKcjNjjgakd5F8+lKRlhfV8+AwlwlAZGDoEQgGWFDXT1DdCmoyEFRIpCMsL6unqH9lQhEDoYSgfR67s7amnqGKRGIHBQlAun11tbWs3VnoxaTFzlISgTS6/1m9iqAtjuGReTAKBFIr7Zqyy7ufHEZAEcN01oCIgdDiUB6tbmrtgIw8x+PJz9Hl46KHAzdUCa90pYdDby6bDNPzV9HYV4254wbEnVIIr2WEoH0Sj947j0eCscGzjhikBaVETkESgTSK721ahsnHz6Q//j4BF02KnKIlAikR5i/uoY3/r4FgH4FuUw7oQKzD77lt7Y6//v2Ok4dU8bjb63hvQ3bueasMYwq6xtVyCIZQ4lAeoRvPbaAJRu2t22PGVzElMqBbduPv7WGbzw6n2H9C1hXW092lnHaWC0sI9IVdNWQRG5HQzPvbdzO1WeN5pVvnQVA1eqaPY55f9MOANbV1lMxsA8Lb72AE0cN3OtcInLg1CKQbjd/dQ1/mL+2bXvLzkbcYcrIgVQMLOSw/gU8Nrea9eHU0gAvLtnY9npieYlmGRXpQkoE0u3+++VlPLdoA4VJH+YVA/sweeQAAD468TB+9frKtquCEorzc8DggqOHdmu8IplOiUC63fraek4bU8Yvrzop5f4bp47jxqnjujkqkfjSGIF0u/V19QzV2gEiPYYSgXSr5pZWNm1v0NoBIj2IEoF0q807Gml1tJqYSA+iMQJJi1ueeGeP+wISdje2AEoEIj2JWgTS5TZtb+D+11aysa6BVmePR35uNmcdOYjjwyuERCR6ahFIl1tQHdwMdttlE3TTl0gvoEQgB+Xbjy3gzZVbU+6r291ElsExw7V0pEhvoEQgB2xHQzOPzF3N+GH9Opz07Zjh/SnM05+XSG+g/6lywN5ZU4s7XH/BkZx15OCowxGRQ6REIPv0+vIt/NOD82hqaW0rS7zWYvEimUGJQPbphcUb2FHfzKdPHrFH+eFlfRnYNy+iqESkKykRCO5OQ3Nryn1Vq2s4eng/bvno0d0clYh0FyUC4ZYnF/LAays73P/5Uyq7LxgR6XZKBELV6hrGDC7issnle+3LMrh00vAIohKR7qJEEIGmllbW1dTTvzCXvnnZrK35YAGW0qI8+uZ37z/L+tp6zjxyEF85c3S3/lwR6RmUCCLwzUfn8/uqtRTn53De0UP43bw1bftGlhby8vVn7rFwezo1t7SyeUeDpoUWibH9zjVkZteYmSaG6UKvLd9Cad88tjc087t5a5hUUcIPPzGRT04pZ+WWXayvq9//SbrIph3BfEBDNC20SGx1ZtK5ocCbZvaImV1oB/BVNTx+iZktM7MbOjjmk2a2yMwWmtmvO3vu3qZmVyNzVmzlxXc3sKGugWknVLTtO3fcYC47vpwrTwwu0Xyiai1zVmxte1StrqGl1dMSV2JdYLUIROJrv11D7n6Tmf0rcD4wHbjLzB4B7nX39zt6n5llA3cD5wHVBMnkSXdflHTMWOBG4FR332ZmGXub6lcfeotXlm5u277omGE8Mmc1m3c0cvzIYGK2ccP6UZiXzW3PvLvX+2+/7FimnTBir/JDtaZmN4AWihGJsU6NEbi7m9l6YD3QDAwAHjOz5939Wx287URgmbsvBzCzh4FLgUVJx3wJuNvdt4U/Z+PBVaNna2l15q7cxtRjh3LliSMoys/h2PL+/P7qU9lQV8/kEUHPW0FuNk9ecxrranfv8f5rH67izRXb0pII3q6uJS87izGDi7r83CLSO+w3EZjZ14DPAZuB/wG+6e5NZpYFLAU6SgTDgdVJ29VA+9XKjwh/xl+BbOA77v7HFDHMAGYAjBjR9R+G6bZs4w52NbZw3vghnD52UFt5+YBCygcU7nHsmMFFe30oT6ooYfbft/L02+tSnn9iRQnDS/ocVGzzq2sYd1g/8nOyD+r9ItL7daZFUAZ83N33uOPI3VvN7OJ9vC/VWEL7ju4cYCxwJlAOvGJmx7h7TbufNROYCTBlypT0dJan0fzVQXUOdm6ek0YN5MV3N/JPD85Luf+U0aX8+ksnH/B5W1qdt6trufz4ve8fEJH46EwieBpom3jezIqB8e7+hrsv3sf7qoGKpO1yYG2KY1539ybg72a2hCAxvNmZ4HuLquoa+hXkUFmaesrm/fni6YdzzrjBtKSYBeJnf36fPy5cT0urk511YJecvr9pBzsbW5hYocnjROKsM4ngp8DkpO2dKcpSeRMYa2ajgDXAFcCn2h3ze+BK4BdmVkbQVbS8EzH1eC++u4FVW3YB8OrSzUysKCHrAD+oE7KzjDGDi1PuO21sGb97aw13vrCUAYW5+zzP4H4FTD12WNt2VdhSmaBZREVirTOJwNy9rTsm7BLqzNVGzWZ2DfAsQf//LHdfaGbfBea4+5PhvvPNbBHQQjD+sOWgatKD1Oxq5Kr75+BJnVifPik9YxsnjhpIXk4Wd7ywtFPH//mbZzIybJksqK6hOD+HwztYXEZE4qEziWB5OGD803D7n+jkt3Z3f5qgaym57Oak1w5cFz4yxoLqYOGWmf94PCdUDiTLjP77+bZ+sMoHFFJ183k0NKWePTRh6cYdfPJnr1G1uqYtEcxfXcuEiv4H3VIRkczQmUTwZeBO4CaCwd4XCK/giTt3576/rmDzjoY9yhdU12IGJ48upV9BehJAssK8HAr3szTA5BElFORm8cvXVrJk/XYAFq+rY8aHD097fCLSs3Wmi2cjQf++tLN43Xa++9QisrOM9l+qTxtT1i1JoLNysrO44OihPP32OuZXB2MD+TlZnKmlJkVirzP3ERQAVwFHA223n7r7F9IYV6+Q+EB94bozqOwF/ex3XHEcd1xxXNRhiEgP05m5hn5JMN/QBcCfCS4D3Z7OoHqDTdsbuPmJd+jfJ5eRpYX7f4OISA/VmUQwxt3/Fdjp7vcDHwGOTW9YPd//LlhLU4tz8YRh3TZltIhIOnQmETSFzzVmdgzQH6hMW0S9xPzqWgYX5/P9jx0TdSgiIoekM1cNzQzXI7gJeBIoAv41rVFF4M0VW7n7pWX0zc/h9ssmUJRilbBb/7CQ9zftBOCtVds4aVSpWgMi0uvtMxGEE8vVhbOD/gXI2GsNn6haw8tLNgHwsUnDOW/8kD32r6+t576/rmBkaSEDCvMYM7iIK06oSHUqEZFeZZ+JILyL+BrgkW6KJzIb6hoYWVpI9bbdzF9ds1ciSEzH8ONpk9qmjRYRyQSd6Rp63syuB35DMM8QAO6+teO39D4b6uoZWdqXvnk53P/aCt7bsJ27Pz2Zr/xqHtXbdrF1ZyM5Wcb4Yf2iDlVEpEt1JhEk7he4OqnMybBuovW19Rw1tJgrTqhg5l+W89yiDTy3cAN/WryB40aUMGlgCZNGlFCQq3n7RSSzdObO4lHdEUiUmlta2byjgaHh7JxjBhdx/o//wv2vrQDgh5+YyOGDtIKXiGSmztxZ/NlU5e7+QNeHE42N2xtodRgSrts7elARffOymf33rRQfwjoCIiK9QWe6hk5Iel0AnAPMAzImEby7vg6AseGc/9lZxvc+dgzzVm0LZg/V7JwiksE60zX01eRtM+tPMO1ExnhrVQ1ZBscM/2Ag+OOTy/n4ZC3hKCKZrzMtgvZ2ESwn2evd+cJSfvT8ewAcMaSIwryD+XWIiPRunRkj+AMfLDqfBYwnQ+4rSCQBgFsv0VQRIhJPnfkK/IOk183ASnevTlM83WpkaSErw3WFPzS6NOJoRESi0ZlEsApY5+71AGbWx8wq3X1FWiPrBmMGFbFyyy4mlPePOhQRkch0ZvbRR4HkBXFbwrJeLzFf3P3TT4w2EBGRCHUmEeS4e2NiI3y9nxVye4eG5laOG1HCgL4ZUR0RkYPSmUSwycwuSWyY2aXA5vSF1H0amlvJy+7Mr0BEJHN1Zozgy8CDZnZXuF0NpLzbuLdpaG6lf5+es8C8iEgUOnND2fvAyWZWBJi7Z8x6xY3NreTnqEUgIvG2309BM/t3Mytx9x3uvt3MBpjZ97sjuHRraG4hT4lARGKuM5+CF7l7TWIjXK1savpC6j4NTWoRiIh05lMw28zyExtm1gfI38fxvUZjSyv5OVpfQETirTODxb8CXjCz+8Lt6cD96QspTZp2w+5tUDys7QaChqYWtQhEJPb2+yno7v8JfB8YRzDP0B+BkWmOq+u9/lP40Thorm8ratBgsYhIp7qGANYT3F18GcF6BIvTFlG65AdrDdAQXPTk7mHXkBKBiMRbh11DZnYEcAVwJbCFYPF6c/ezuim2rpWcCIoG09TiuKOrhkQk9vY1RvAu8ArwUXdfBmBmX++WqNKhXYugobklKNZgsYjE3L6+Dl9G0CX0kpn93MzOAXrvmo154eLzbYkgmEcvP1ctAhGJtw4/Bd39cXefBhwFvAx8HRhiZj81s/O7Kb6uk2gRNO4InsJEoLmGRCTuOnPV0E53f9DdLwbKgSrghrRH1tXyw/WI1SIQEdnDAX0KuvtWd/+Zu5+droDSJr9915DGCERE4AATQa/WbrC4vilsEeiqIRGJubR+CprZhWa2xMyWmVmH3UlmdrmZuZlNSVswuYVgWW2JYFdjMwB98tQiEJF4S1siMLNs4G7gIoI7kq80s/EpjisGvga8ka5Ywh8EecVtg8X1TUHXUGFeZ2bZEBHJXOlsEZwILHP35eHylg8Dl6Y47nvAfwL1KfZ1rfzipBZBIhGoRSAi8ZbORDAcWJ20XR2WtTGz44AKd39qXycysxlmNsfM5mzatOngI0qRCPrkKhGISLylMxGkuvnM23aaZQE/Br6xvxO5+0x3n+LuUwYNGnTwEeUXtSWC3YlEoBaBiMRcOhNBNVCRtF0OrE3aLgaOAV42sxXAycCTaR0wzv9gjGB3k7qGREQgvYngTWCsmY0yszyCCeyeTOx091p3L3P3SnevBF4HLnH3OWmLKK9or66hAt1HICIxl7ZE4O7NwDXAswTTVj/i7gvN7Ltmdkm6fu4+5fdL6hpqpk9uNllZvXf6JBGRrpDWayfd/Wng6XZlN3dw7JnpjAUIB4s/6BrS+ICISJzuLIZgsLhxO7izq7FFVwyJiBC7RFAM3gpNu9jd2KKBYhER4pgIABq2s0uJQEQEiFsiyPsgEexuaqFAXUMiIjFLBIkWwYaFZO3cSFG+5hkSEYlXIuhbFjw/+jkeqP0Cx5bp0lERkXglgsMmw6ceZeO4z5FnzRxf1hx1RCIikYtXIsjKgiPOZ2HBZACOGqgWgYhIvBJBaEN9MDZQmtMQcSQiItGLZSJYV58LQFbTzogjERGJXiwTwZpd4dVC4bxDIiJxFstEsGpnWO2GumgDERHpAWJ1If3f3t9M1eoaltUaZNM2AZ2ISJzFKhF867EFVG/bDeTg2VmYuoZEROLTNdTa6qyvrWfGhw9nyfcvwpJWKxMRibPYJIItOxtpbnWGl/QhPyd7j4XsRUTiLDaJYENdPQBD+uUHBflFUPUgbF8fYVQiItGLYSIoCAoOOy54Xv1GRBGJiPQMsUkE68NEMLR/mAhO/0bw3NwYUUQiIj1DbBJBTpZRWVrIoKKwayg7L3hu0TQTIhJvsbl8dNoJI5h2wogPCtoSgVoEIhJvsWkR7CUnbBmoa0hEYi6+iUBdQyIiQJwTgVoEIiJAnBNBVg5gahGISOzFNxGYBd1DGiwWkZiLbyKAoHtIXTn2ReYAAAlrSURBVEMiEnOxuXw0pew8aN4Na+aFLQODYRMgt0/UkYmIdJt4J4KcfFj4e5j7iw/KTv1nOO/WyEISEelu8e4ays6D+prg9eX3QZ+BsGtLtDGJiHQzJYKEIy4MZiTV4LGIxEy8E0FOmAgsOxgXyM5XIhCR2Il3IshOWpvATFcRiUgsxTsRJO4uzu8XPGfn6QYzEYmdeCeCxBhBfnHwnJMPzUoEIhIvSgTwQSLIztUYgYjETrwTQWKwOK8oeNZgsYjEUFoTgZldaGZLzGyZmd2QYv91ZrbIzBaY2QtmNjKd8eylbbA4uWtIiUBE4iVticDMsoG7gYuA8cCVZja+3WFvAVPcfQLwGPCf6YonpZx2iUCDxSISQ+lsEZwILHP35e7eCDwMXJp8gLu/5O67ws3XgfI0xrO3lIPFahGISLykc66h4cDqpO1q4KR9HH8V8EyqHWY2A5gBMGLEiFSHHJzxl0DNKjjq4mA7O1ctAhGJnXQmAktR5ikPNPsMMAU4I9V+d58JzASYMmVKynMclNFnB48EDRaLSAylMxFUAxVJ2+XA2vYHmdm5wL8AZ7h7tF/H1TUkIjGUzjGCN4GxZjbKzPKAK4Ankw8ws+OAnwGXuPvGNMbSORosFpEYSlsicPdm4BrgWWAx8Ii7LzSz75rZJeFh/w8oAh41syoze7KD03WPnHxobYbW1kjDEBHpTmldmMbdnwaebld2c9Lrc9P58w9Ydm7w3NIAWVqlTETiId53FreXuMFMA8YiEiNKBMkSN5hpwFhEYkSJIFniBjMNGItIjCgRJGtrESgRiEh8pHWwuNdJDBa//yI07oRhE6KNJwo7t0D17KijEJFUBo+HAV0/N6cSQbK+g4Lnp68PBo5vrP5gquq4eO4mmP/rqKMQkVQ+8iM44aouP60SQbLK0+Hq2VD1IPz1DmjYDjmlUUfVvXZuhEFHwT/cE3UkItJe/4r9H3MQlAiSmcGgI4MPQoDG7dA3ZomgYQcUDYbDjos6EhHpJhosTiUxLXXD9mjjiELDdsjvF3UUItKNlAhSSSxdGcdE0Lj9g/qLSCwoEaSS+EbcsCPaOKLQsP2DFpGIxIISQSr5iRZBXbRxdDf3IPkpEYjEihJBKnEdI2hugNamDxKhiMSCEkEqiT7yxph1DSUSnwaLRWJFiSCVuA4WNyYSgbqGROJEiSCVrCzIK45fIkjUV1cNicSKbijrSH5RcIfx+y9GHUn3adoVPGuMQCRWlAg6ctp1sPLVqKPofpUfhuHHRx2FiHQjJYKOnDQjeIiIZDiNEYiIxJwSgYhIzCkRiIjEnBKBiEjMKRGIiMScEoGISMwpEYiIxJwSgYhIzJm7Rx3DATGzTcDKg3x7GbC5C8PpDVTneFCd4+FQ6jzS3Qel2tHrEsGhMLM57j4l6ji6k+ocD6pzPKSrzuoaEhGJOSUCEZGYi1simBl1ABFQneNBdY6HtNQ5VmMEIiKyt7i1CEREpB0lAhGRmItNIjCzC81siZktM7Mboo6nq5jZLDPbaGbvJJUNNLPnzWxp+DwgLDczuzP8HSwws8nRRX7wzKzCzF4ys8VmttDMrg3LM7beZlZgZrPNbH5Y51vD8lFm9kZY59+YWV5Ynh9uLwv3V0YZ/8Eys2wze8vMngq3M7q+AGa2wszeNrMqM5sTlqX1bzsWicDMsoG7gYuA8cCVZjY+2qi6zC+AC9uV3QC84O5jgRfCbQjqPzZ8zAB+2k0xdrVm4BvuPg44Gbg6/PfM5Ho3AGe7+0RgEnChmZ0M3A78OKzzNuCq8PirgG3uPgb4cXhcb3QtsDhpO9Prm3CWu09KumcgvX/b7p7xD+BDwLNJ2zcCN0YdVxfWrxJ4J2l7CTAsfD0MWBK+/hlwZarjevMDeAI4Ly71BgqBecBJBHeZ5oTlbX/nwLPAh8LXOeFxFnXsB1jP8vBD72zgKcAyub5J9V4BlLUrS+vfdixaBMBwYHXSdnVYlqmGuPs6gPB5cFiecb+HsAvgOOANMrzeYTdJFbAReB54H6hx9+bwkOR6tdU53F8LlHZvxIfsv4BvAa3hdimZXd8EB54zs7lmllg4Pa1/23FZvN5SlMXxutmM+j2YWRHwW+Cf3b3OLFX1gkNTlPW6ert7CzDJzEqAx4FxqQ4Ln3t1nc3sYmCju881szMTxSkOzYj6tnOqu681s8HA82b27j6O7ZJ6x6VFUA1UJG2XA2sjiqU7bDCzYQDh88awPGN+D2aWS5AEHnT334XFGV9vAHevAV4mGB8pMbPEF7rkerXVOdzfH9javZEeklOBS8xsBfAwQffQf5G59W3j7mvD540ECf9E0vy3HZdE8CYwNrziIA+4Angy4pjS6Ungc+HrzxH0oSfKPxteaXAyUJtobvYmFnz1vxdY7O4/StqVsfU2s0FhSwAz6wOcSzCI+hJweXhY+zonfheXAy962IncG7j7je5e7u6VBP9fX3T3T5Oh9U0ws75mVpx4DZwPvEO6/7ajHhjpxgGYqcB7BP2q/xJ1PF1Yr4eAdUATwbeDqwj6Rl8AlobPA8NjjeDqqfeBt4EpUcd/kHU+jaD5uwCoCh9TM7newATgrbDO7wA3h+WHA7OBZcCjQH5YXhBuLwv3Hx51HQ6h7mcCT8WhvmH95oePhYnPqnT/bWuKCRGRmItL15CIiHRAiUBEJOaUCEREYk6JQEQk5pQIRERiTolApB0zawlnfkw8umy2WjOrtKSZYkV6grhMMSFyIHa7+6SogxDpLmoRiHRSOE/87eG6ALPNbExYPtLMXgjng3/BzEaE5UPM7PFwDYH5ZnZKeKpsM/t5uK7Ac+GdwiKRUSIQ2Vufdl1D05L21bn7icBdBHPfEL5+wN0nAA8Cd4bldwJ/9mANgckEd4pCMHf83e5+NFADXJbm+ojsk+4sFmnHzHa4e1GK8hUEi8MsDye9W+/upWa2mWAO+KawfJ27l5nZJqDc3RuSzlEJPO/BAiOY2beBXHf/fvprJpKaWgQiB8Y7eN3RMak0JL1uQWN1EjElApEDMy3p+bXw9d8IZsgE+DTwavj6BeAr0LaoTL/uClLkQOibiMje+oQrgSX80d0Tl5Dmm9kbBF+irgzLvgbMMrNvApuA6WH5tcBMM7uK4Jv/VwhmihXpUTRGINJJ4RjBFHffHHUsIl1JXUMiIjGnFoGISMypRSAiEnNKBCIiMadEICISc0oEIiIxp0QgIhJz/x+leAJcKLLZkQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(test.history['accuracy'])\n",
    "plt.plot(test.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(test.history['loss'])\n",
    "plt.plot(test.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value = Price*Stock \n",
    "Asset差距\n",
    "\n",
    "要放嗎?\n",
    "可能的問題:\n",
    "1. Sample數不夠\n",
    "2. 選的變項根本沒關係\n",
    "\n",
    "用ANOVA找有顯著的變項\n",
    "\n",
    "先設定單一策略去進行實驗做出data在train model確保model可以預測該進行策略->用於debug(因為已經知道答案)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
